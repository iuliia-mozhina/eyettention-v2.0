{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "nuclear-dream",
      "metadata": {
        "id": "nuclear-dream"
      },
      "source": [
        "# Eyettention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0978c758-ea14-4df4-97d0-6e0c1ed18428",
      "metadata": {
        "id": "0978c758-ea14-4df4-97d0-6e0c1ed18428"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import model\n",
        "import torch\n",
        "from torch.utils import model_zoo\n",
        "import pandas as pd\n",
        "from utils import *\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam, RMSprop\n",
        "from transformers import BertTokenizerFast\n",
        "from model import Eyettention\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from torch.nn.functional import cross_entropy, softmax\n",
        "from collections import deque, Counter\n",
        "import pickle\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import random\n",
        "from scasim import *\n",
        "from evaluate_e_z_reader_model import *\n",
        "from uniform_model import *\n",
        "from evaluate_swift import *\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8dfb0f8-8775-4609-b75c-6052916ca9c0",
      "metadata": {
        "id": "c8dfb0f8-8775-4609-b75c-6052916ca9c0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "save_data_folder = \"./drive/MyDrive/results/celer/New_Reader\"\n",
        "#DEVICE = 'cuda'\n",
        "DEVICE = 'cpu'\n",
        "#test_mode = 'text'\n",
        "test_mode = 'subject'\n",
        "scanpath_gen_flag = True\n",
        "atten_type = \"local_g\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4l7DoNdYwUn9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l7DoNdYwUn9",
        "outputId": "9af1faf2-6a89-44e7-acc3-c4b05c283159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e085041-7c16-44b4-9129-bf667f64c552",
      "metadata": {
        "id": "6e085041-7c16-44b4-9129-bf667f64c552"
      },
      "source": [
        "**Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28WYhnrePEZj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ed779e65e0244b2c804670d80fd43941",
            "c850219e15b74090a2c7a5b09169b263",
            "26a35d039347436b87a63fbd884cad98",
            "b02c0a217c4140e296e54c9e87530c02",
            "936becaad1e4421d9d35524ccbd33af0",
            "3f99f01470094e4db369df53b964b64d",
            "0a2a5267af984eadb209020a6d65054d",
            "70603e4b6f64488d8a9542bef926bbeb",
            "948b18569e7d4f53be9f0b290f798d2c",
            "5c531120925d428b82e123d9a3889e2a",
            "178ebf8ce8a040b48f87cfd7e3aa6d42",
            "1034d5c1f16d432686a1584c04774796",
            "04941b5000214b5bb7d3b649c35b32f4",
            "a9f9299003114b0db7f551d3c2849d93",
            "75ede2edfec14179af72a6ef8b23971c",
            "2e29123734714afbba6465f1331b2b11",
            "8a0fcbd640524a31b468a3f941b9a11b",
            "d44e32edab314dc3a0b4a4491d8627d0",
            "f5fe405759c44a30a4d361017700fd8b",
            "43ffdd89658b4fe78487013558d8ba89",
            "8d0ef8c79a23429f98dd875cd8955348",
            "6c3d7d1f34894ebab94d94dc56720a62",
            "520ec5afdb3d4d41981197585e2c4557",
            "ca0369599e8b44baa9acc3878b1214f7",
            "089f664d5bb44d0589a233e2fc61f6e6",
            "3caf567beddf4a528b28d0e549e3bcda",
            "9d322dfd054d43f2828b7dc9fa088e61",
            "ea53ac6939e344719214a466fc109237",
            "60b6d79ea74649de81c3ab4496889c06",
            "ca482e85ad704a76b0b4241e57a0a2c3",
            "4a510322d6504fb28832aeb7ea0eeffc",
            "af80c298cce64c578fe8facbbf55e54b",
            "e1fd2e9e2c7e4f5688082395f6f1289f",
            "77f95906afd743f283004fe7a63fc740",
            "65f9af198f3b423f9cfbd1114a06e5a9",
            "dec3e1f095cb454ba3f4d6bc4eda4e1f",
            "3abb9356d90a4d13867fdb24bbafb9c9",
            "a8153ee371c045febf3771f3696c24fa",
            "af16bde493af4b28b129b6be884a2489",
            "48b927397c2b443ca9c9934d7987d649",
            "cebe26b277f04bf1bd084f30734b5c41",
            "f37ca9aaf4524b6997146b187a270a4e",
            "c7027c79882b4320a23fd0376f98812e",
            "8cbadab4b26f4a9098e21ffeb38aad0d",
            "cf699a56c6eb468d87db86ded607dfa5",
            "5c138ce3ac2c468599e9014c05843e65",
            "7d48e5c6540243d887bbc03c88ffb16b",
            "531ece5c80dd46fea721265223c3d2c0",
            "f18fb33cfba04655befa99ac7624a087",
            "17ba8d7aaa6545a3af29a00d666e5890",
            "f3b0d75866724b01978763396123b2d4",
            "404b9a055c7d410da0d7e90f6990565f",
            "3c7f975e248749cda8039b83b4619e67",
            "88a0cf764880430b950da216ea29a47a",
            "4578a38620e9457385642e1950208ec3"
          ]
        },
        "id": "28WYhnrePEZj",
        "outputId": "9b355ec2-cf06-4abe-fcc8-ae8dcf471b17"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "/content/utils.py:38: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start evaluating on new readers.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed779e65e0244b2c804670d80fd43941",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1034d5c1f16d432686a1584c04774796",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "520ec5afdb3d4d41981197585e2c4557",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77f95906afd743f283004fe7a63fc740",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5456/5456 [19:41<00:00,  4.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keeping Bert with pre-trained weights\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf699a56c6eb468d87db86ded607dfa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.07714836428476701\n",
            "MSE for landing positions 0.041626496263234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.0938066546459595\n",
            "MSE for landing positions 0.042226213228786946\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.16407840290276\n",
            "MSE for landing positions 0.0296699824029929\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2908.58\n",
            "Mean scasim human 3058.4466666666667\n",
            "Mean central scasim dnn 1800.9666666666667\n",
            "Mean central scasim human 2426.8933333333334\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2238.269230769231\n",
            "Mean scasim score SWIFT 3719.5307692307692\n",
            "MSE for durations SWIFT 3.253278688971813\n",
            "MSE for landing pos SWIFT 1.5870385234172528\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2497. Using all available scanpaths.\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2493. Using all available scanpaths.\n",
            "NLL SWIFT -5380207.565573771\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.05884979678603486\n",
            "MSE for landing positions 0.027036989219141105\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2523.3607843137256\n",
            "Mean scasim human 2322.0666666666666\n",
            "Mean central scasim dnn 1817.1686274509805\n",
            "Mean central scasim human 1881.2235294117647\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2130.718061674009\n",
            "Mean scasim score SWIFT 3299.2687224669603\n",
            "MSE for durations SWIFT 1.8172360976362019\n",
            "MSE for landing pos SWIFT 1.5932652414632789\n",
            "NLL SWIFT -5314854.62745098\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.07246617158580193\n",
            "MSE for landing positions 0.030261952607133935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2636.66796875\n",
            "Mean scasim human 3353.70703125\n",
            "Mean central scasim dnn 1979.1953125\n",
            "Mean central scasim human 1944.0234375\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2241.7965367965367\n",
            "Mean scasim score SWIFT 3433.4632034632036\n",
            "MSE for durations SWIFT 1.8829881384388192\n",
            "MSE for landing pos SWIFT 1.6029043109902055\n",
            "NLL SWIFT -5169318.78515625\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.06652706986551493\n",
            "MSE for landing positions 0.03440398646307585\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2973.32421875\n",
            "Mean scasim human 3320.84765625\n",
            "Mean central scasim dnn 2040.36328125\n",
            "Mean central scasim human 2189.22265625\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2772.817021276596\n",
            "Mean scasim score SWIFT 3840.3063829787234\n",
            "MSE for durations SWIFT 1.8031374788664758\n",
            "MSE for landing pos SWIFT 1.6137606666443196\n",
            "Requested count (13) exceeds available scanpaths (0) for sentence 2557. Using all available scanpaths.\n",
            "NLL SWIFT -5503104.390946502\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.05502577135166575\n",
            "MSE for landing positions 0.0352668865079977\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2698.855421686747\n",
            "Mean scasim human 3421.8132530120483\n",
            "Mean central scasim dnn 1988.4638554216867\n",
            "Mean central scasim human 2054.385542168675\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2338.3424657534247\n",
            "Mean scasim score SWIFT 3291.671232876712\n",
            "MSE for durations SWIFT 1.6473145728854284\n",
            "MSE for landing pos SWIFT 1.687305454521963\n",
            "NLL SWIFT -5411615.4397590365\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.0624818453543412\n",
            "MSE for landing positions 0.037182636005582026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.04871717913144986\n",
            "MSE for landing positions 0.032786297600441536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SWIFT NLL -5346066.595009597\n",
            "Standard error for SWIFT NLL 19849.646912280838\n",
            "SWIFT central scasim 2358.630546955624\n",
            "Standard error for SWIFT central scasim 49.631306906790535\n",
            "SWIFT scasim 3517.7079463364294\n",
            "Standard error for SWIFT scasim 57.90327661860335\n",
            "SWIFT MSE durations 1.9965472847100258\n",
            "Standard error for SWIFT MSE durations 0.13817399760596405\n",
            "SWIFT MSE landing pos 1.6138673547128652\n",
            "Standard error for SWIFT MSE landing pos 0.004840117275063015\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5456/5456 [20:16<00:00,  4.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 1.1622655606356602\n",
            "MSE for landing positions 0.029264660630360595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.633759440639551\n",
            "MSE for landing positions 0.09308141846940998\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2183.3333333333335\n",
            "Mean scasim human 2670.2444444444445\n",
            "Mean central scasim dnn 1746.5333333333333\n",
            "Mean central scasim human 1220.6\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 1942.275\n",
            "Mean scasim score SWIFT 2372.45\n",
            "MSE for durations SWIFT 1.2575480233877898\n",
            "MSE for landing pos SWIFT 1.6094859421253205\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2493. Using all available scanpaths.\n",
            "NLL SWIFT -5241010.774193549\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.07553314904362196\n",
            "MSE for landing positions 0.023875661101556034\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2690.39453125\n",
            "Mean scasim human 2608.95703125\n",
            "Mean central scasim dnn 1867.4921875\n",
            "Mean central scasim human 2058.90234375\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2279.7012987012986\n",
            "Mean scasim score SWIFT 3277.4718614718613\n",
            "MSE for durations SWIFT 2.008376310414179\n",
            "MSE for landing pos SWIFT 1.59856898753674\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2497. Using all available scanpaths.\n",
            "NLL SWIFT -5346430.450413223\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.03621118297508019\n",
            "MSE for landing positions 0.022472155677860428\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2276.29296875\n",
            "Mean scasim human 2617.5390625\n",
            "Mean central scasim dnn 1610.62109375\n",
            "Mean central scasim human 1653.4921875\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 1963.1377777777777\n",
            "Mean scasim score SWIFT 2862.871111111111\n",
            "MSE for durations SWIFT 1.5034160044789315\n",
            "MSE for landing pos SWIFT 1.6507446405622694\n",
            "NLL SWIFT -5258718.80859375\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.03857491974304139\n",
            "MSE for landing positions 0.02737069476461329\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2907.3203125\n",
            "Mean scasim human 3489.6953125\n",
            "Mean central scasim dnn 1984.171875\n",
            "Mean central scasim human 2131.296875\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2671.536170212766\n",
            "Mean scasim score SWIFT 3779.08085106383\n",
            "MSE for durations SWIFT 1.5168316313719497\n",
            "MSE for landing pos SWIFT 1.6404065573469122\n",
            "NLL SWIFT -5382667.328125\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.04253684538844027\n",
            "MSE for landing positions 0.0248628592953537\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2949.43359375\n",
            "Mean scasim human 3817.3671875\n",
            "Mean central scasim dnn 2169.2265625\n",
            "Mean central scasim human 2119.67578125\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2771.315789473684\n",
            "Mean scasim score SWIFT 3777.6973684210525\n",
            "MSE for durations SWIFT 1.4581636063787236\n",
            "MSE for landing pos SWIFT 1.656679700341141\n",
            "Requested count (13) exceeds available scanpaths (0) for sentence 2557. Using all available scanpaths.\n",
            "NLL SWIFT -5438024.152263374\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.06138073350302875\n",
            "MSE for landing positions 0.03241254611657496\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 3367.909090909091\n",
            "Mean scasim human 2214.818181818182\n",
            "Mean central scasim dnn 3129.909090909091\n",
            "Mean central scasim human 1541.3636363636363\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2417.6666666666665\n",
            "Mean scasim score SWIFT 2737.4444444444443\n",
            "MSE for durations SWIFT 1.2779475185606215\n",
            "MSE for landing pos SWIFT 1.6283996370103624\n",
            "NLL SWIFT -4884219.7272727275\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.03774775256124485\n",
            "MSE for landing positions 0.02930073706920666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.03835635517676865\n",
            "MSE for landing positions 0.07333526099442479\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SWIFT NLL -5347130.548604427\n",
            "Standard error for SWIFT NLL 19841.614716054304\n",
            "SWIFT central scasim 2404.378099173554\n",
            "Standard error for SWIFT central scasim 51.98080543773534\n",
            "SWIFT scasim 3378.280991735537\n",
            "Standard error for SWIFT scasim 63.62536212500659\n",
            "SWIFT MSE durations 1.6042600340317659\n",
            "Standard error for SWIFT MSE durations 0.06798356607392232\n",
            "SWIFT MSE landing pos 1.6352691397932935\n",
            "Standard error for SWIFT MSE landing pos 0.005443925924107844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5456/5456 [19:58<00:00,  4.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.05717592151086137\n",
            "MSE for landing positions 0.03573304463043314\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.061846098287787754\n",
            "MSE for landing positions 0.026896113660541232\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2168.6382978723404\n",
            "Mean scasim human 2876.021276595745\n",
            "Mean central scasim dnn 1523.6808510638298\n",
            "Mean central scasim human 1717.2340425531916\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 1928.9285714285713\n",
            "Mean scasim score SWIFT 2851.8809523809523\n",
            "MSE for durations SWIFT 3.407557487310398\n",
            "MSE for landing pos SWIFT 1.624270918823424\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2493. Using all available scanpaths.\n",
            "NLL SWIFT -5228614.818181818\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.055964941124329926\n",
            "MSE for landing positions 0.022213689525869995\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2619.19140625\n",
            "Mean scasim human 2641.87109375\n",
            "Mean central scasim dnn 1764.6328125\n",
            "Mean central scasim human 2100.34375\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2313.1531914893617\n",
            "Mean scasim score SWIFT 3359.5574468085106\n",
            "MSE for durations SWIFT 1.9679095289491593\n",
            "MSE for landing pos SWIFT 1.5611214866029455\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2497. Using all available scanpaths.\n",
            "NLL SWIFT -5354551.061983471\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.1374674889684684\n",
            "MSE for landing positions 0.025372984425303002\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2218.16796875\n",
            "Mean scasim human 2641.11328125\n",
            "Mean central scasim dnn 1525.61328125\n",
            "Mean central scasim human 1688.41796875\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 1889.8755555555556\n",
            "Mean scasim score SWIFT 2916.5822222222223\n",
            "MSE for durations SWIFT 2.3026836994952626\n",
            "MSE for landing pos SWIFT 1.6156660148832533\n",
            "NLL SWIFT -5309036.55078125\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.08030745499308978\n",
            "MSE for landing positions 0.03147033016921341\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2737.0078125\n",
            "Mean scasim human 3450.65625\n",
            "Mean central scasim dnn 1952.1171875\n",
            "Mean central scasim human 2063.32421875\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2699.7719298245615\n",
            "Mean scasim score SWIFT 3654.7412280701756\n",
            "MSE for durations SWIFT 1.877880814093116\n",
            "MSE for landing pos SWIFT 1.6074587383814025\n",
            "NLL SWIFT -5289490.296875\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.06097151575704629\n",
            "MSE for landing positions 0.039346511923213257\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2741.546875\n",
            "Mean scasim human 3713.87109375\n",
            "Mean central scasim dnn 1974.48828125\n",
            "Mean central scasim human 2051.5546875\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2562.1201716738196\n",
            "Mean scasim score SWIFT 3591.248927038627\n",
            "MSE for durations SWIFT 1.829017502043892\n",
            "MSE for landing pos SWIFT 1.6491055744400351\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2557. Using all available scanpaths.\n",
            "NLL SWIFT -5484282.863636363\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.06001785934859072\n",
            "MSE for landing positions 0.03775504587247269\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 1942.4736842105262\n",
            "Mean scasim human 2339.157894736842\n",
            "Mean central scasim dnn 1392.0\n",
            "Mean central scasim human 1430.2631578947369\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 1763.1176470588234\n",
            "Mean scasim score SWIFT 2105.0588235294117\n",
            "MSE for durations SWIFT 1.6572220351766138\n",
            "MSE for landing pos SWIFT 1.5862076773363\n",
            "NLL SWIFT -4839826.105263158\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.1092352970445063\n",
            "MSE for landing positions 0.03391991601984046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.07358021304632227\n",
            "MSE for landing positions 0.035531875863310323\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SWIFT NLL -5344200.064885496\n",
            "Standard error for SWIFT NLL 20304.783107806867\n",
            "SWIFT central scasim 2339.1051020408163\n",
            "Standard error for SWIFT central scasim 49.784937085576765\n",
            "SWIFT scasim 3338.0959183673467\n",
            "Standard error for SWIFT scasim 60.9764886906084\n",
            "SWIFT MSE durations 2.0471129227999825\n",
            "Standard error for SWIFT MSE durations 0.13203658422061051\n",
            "SWIFT MSE landing pos 1.608485207144095\n",
            "Standard error for SWIFT MSE landing pos 0.0051299165948368395\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5456/5456 [20:00<00:00,  4.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.2313541651219566\n",
            "MSE for landing positions 0.029389661874120065\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.43389062605729123\n",
            "MSE for landing positions 0.03297801619828533\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.06563226062098693\n",
            "MSE for landing positions 0.02862896403621562\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2373.708520179372\n",
            "Mean scasim human 2637.6053811659194\n",
            "Mean central scasim dnn 1735.3094170403588\n",
            "Mean central scasim human 1857.847533632287\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2342.4378109452737\n",
            "Mean scasim score SWIFT 3221.9004975124376\n",
            "MSE for durations SWIFT 1.4458518609478699\n",
            "MSE for landing pos SWIFT 1.6000376299246033\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2497. Using all available scanpaths.\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2493. Using all available scanpaths.\n",
            "NLL SWIFT -5356272.153846154\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.13215212839804735\n",
            "MSE for landing positions 0.027022327313716232\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2103.9764705882353\n",
            "Mean scasim human 2118.450980392157\n",
            "Mean central scasim dnn 1557.1568627450981\n",
            "Mean central scasim human 1524.3921568627452\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 1887.1576763485477\n",
            "Mean scasim score SWIFT 2579.51867219917\n",
            "MSE for durations SWIFT 2.233995394309774\n",
            "MSE for landing pos SWIFT 1.6033384171758944\n",
            "NLL SWIFT -5249761.835294117\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.09991810691144565\n",
            "MSE for landing positions 0.0334231656315751\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2689.15234375\n",
            "Mean scasim human 3659.0703125\n",
            "Mean central scasim dnn 2167.17578125\n",
            "Mean central scasim human 1691.28515625\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2521.3760683760684\n",
            "Mean scasim score SWIFT 3295.4529914529912\n",
            "MSE for durations SWIFT 2.7455837227340436\n",
            "MSE for landing pos SWIFT 1.607955074717856\n",
            "NLL SWIFT -5258708.4453125\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.459958825992544\n",
            "MSE for landing positions 0.03323444315719826\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 3018.76953125\n",
            "Mean scasim human 3500.88671875\n",
            "Mean central scasim dnn 2221.33203125\n",
            "Mean central scasim human 2007.9765625\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2704.8577586206898\n",
            "Mean scasim score SWIFT 3550.8663793103447\n",
            "MSE for durations SWIFT 2.534701755270362\n",
            "MSE for landing pos SWIFT 1.589344944419532\n",
            "Requested count (14) exceeds available scanpaths (0) for sentence 2557. Using all available scanpaths.\n",
            "NLL SWIFT -5567810.384297521\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.1404199976750533\n",
            "MSE for landing positions 0.03037910198327154\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2641.25\n",
            "Mean scasim human 3041.35\n",
            "Mean central scasim dnn 2006.16\n",
            "Mean central scasim human 1776.61\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2152.8901098901097\n",
            "Mean scasim score SWIFT 2995.747252747253\n",
            "MSE for durations SWIFT 2.3413365136136064\n",
            "MSE for landing pos SWIFT 1.671255342252962\n",
            "NLL SWIFT -5255534.69\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.04787123150617845\n",
            "MSE for landing positions 0.03249609163231071\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.05875488650406513\n",
            "MSE for landing positions 0.03426940353396772\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SWIFT NLL -5345758.856870229\n",
            "Standard error for SWIFT NLL 20328.56030755315\n",
            "SWIFT central scasim 2341.4184184184182\n",
            "Standard error for SWIFT central scasim 50.526486954300545\n",
            "SWIFT scasim 3139.955955955956\n",
            "Standard error for SWIFT scasim 57.067883559728244\n",
            "SWIFT MSE durations 2.2748629981586643\n",
            "Standard error for SWIFT MSE durations 0.30034599578902393\n",
            "SWIFT MSE landing pos 1.6066925654540192\n",
            "Standard error for SWIFT MSE landing pos 0.004882598947918501\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5456/5456 [20:12<00:00,  4.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.11148378079451504\n",
            "MSE for landing positions 0.036116293725172\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.19100366872589802\n",
            "MSE for landing positions 0.04002440465410473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2680.9919354838707\n",
            "Mean scasim human 3091.6532258064517\n",
            "Mean central scasim dnn 1763.6774193548388\n",
            "Mean central scasim human 2235.5806451612902\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2334.141592920354\n",
            "Mean scasim score SWIFT 3664.5398230088495\n",
            "MSE for durations SWIFT 2.474770693058989\n",
            "MSE for landing pos SWIFT 1.5859261002160807\n",
            "Requested count (13) exceeds available scanpaths (0) for sentence 2497. Using all available scanpaths.\n",
            "Requested count (13) exceeds available scanpaths (0) for sentence 2493. Using all available scanpaths.\n",
            "NLL SWIFT -5446288.153061224\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.13619065379498352\n",
            "MSE for landing positions 0.04039057654699718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2298.7578125\n",
            "Mean scasim human 2318.3984375\n",
            "Mean central scasim dnn 1519.8046875\n",
            "Mean central scasim human 1847.171875\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2032.874458874459\n",
            "Mean scasim score SWIFT 3191.6796536796537\n",
            "MSE for durations SWIFT 2.0174395633272795\n",
            "MSE for landing pos SWIFT 1.6003241301615\n",
            "NLL SWIFT -5263203.5078125\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.13101629496304668\n",
            "MSE for landing positions 0.03645885378045932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2468.5234375\n",
            "Mean scasim human 3471.01953125\n",
            "Mean central scasim dnn 1642.453125\n",
            "Mean central scasim human 1961.15234375\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2215.9184549356223\n",
            "Mean scasim score SWIFT 3422.3733905579397\n",
            "MSE for durations SWIFT 1.8406299236250538\n",
            "MSE for landing pos SWIFT 1.6165477825336703\n",
            "NLL SWIFT -5197465.984375\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.13201900279455003\n",
            "MSE for landing positions 0.04046847287645505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 3055.72265625\n",
            "Mean scasim human 3490.84375\n",
            "Mean central scasim dnn 1958.921875\n",
            "Mean central scasim human 2332.12109375\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2712.716814159292\n",
            "Mean scasim score SWIFT 4019.1946902654868\n",
            "MSE for durations SWIFT 1.7797492081217006\n",
            "MSE for landing pos SWIFT 1.61976133985857\n",
            "Requested count (13) exceeds available scanpaths (0) for sentence 2557. Using all available scanpaths.\n",
            "NLL SWIFT -5557008.004115227\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.146064032049253\n",
            "MSE for landing positions 0.043802611494356825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n",
            "/content/scasim.py:101: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  eyemovement_df = pd.read_csv('drive/MyDrive/celer/sent_fix.tsv', delimiter='\\t')  # TODO ././Data/celer/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######### Eyettention model evaluation ##########\n",
            "Mean scasim dnn 2630.6168224299067\n",
            "Mean scasim human 3299.4018691588785\n",
            "Mean central scasim dnn 1807.607476635514\n",
            "Mean central scasim human 2010.1682242990655\n",
            "######### SWIFT model evaluation ##########\n",
            "Central scasim SWIFT 2166.548387096774\n",
            "Mean scasim score SWIFT 3193.989247311828\n",
            "MSE for durations SWIFT 1.8845467753307794\n",
            "MSE for landing pos SWIFT 1.695968863784626\n",
            "NLL SWIFT -5307958.897196262\n",
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.1491517902140913\n",
            "MSE for landing positions 0.05362839068766334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uniform_nll -5.4918532371521 [-5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521, -5.4918532371521]\n",
            "######### Eyettention 2.0 model evaluation ##########\n",
            "MSE for durations 0.11686469582352965\n",
            "MSE for landing positions 0.044210541790484316\n",
            "SWIFT NLL -5343721.016666667\n",
            "Standard error for SWIFT NLL 20718.603710855616\n",
            "SWIFT central scasim 2303.8214285714284\n",
            "Standard error for SWIFT central scasim 52.91898701080846\n",
            "SWIFT scasim 3520.2712053571427\n",
            "Standard error for SWIFT scasim 65.42509561728423\n",
            "SWIFT MSE durations 1.9553912620426022\n",
            "Standard error for SWIFT MSE durations 0.07376058638444712\n",
            "SWIFT MSE landing pos 1.6175572810960668\n",
            "Standard error for SWIFT MSE landing pos 0.005007650403870424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\tgpu = 0\n",
        "\n",
        "\ttorch.set_default_tensor_type('torch.FloatTensor')\n",
        "\tavailbl = torch.cuda.is_available()\n",
        "\tif availbl:\n",
        "\t\tdevice = f'cuda:{gpu}'\n",
        "\telse:\n",
        "\t\tdevice = 'cpu'\n",
        "\t#torch.cuda.set_device(gpu)\n",
        "\n",
        "\tcf = {\"model_pretrained\": \"bert-base-cased\",\n",
        "\t\t\t\"lr\": 1e-3,\n",
        "\t\t\t\"max_grad_norm\": 10,\n",
        "\t\t\t\"n_epochs\": 200,  # 1000\n",
        "\t\t\t\"n_folds\": 5,\n",
        "\t\t\t\"dataset\": 'celer',\n",
        "\t\t\t\"atten_type\": 'local-g',\n",
        "\t\t\t\"batch_size\": 256,\n",
        "\t\t\t\"max_sn_len\": 24, #include start token and end token\n",
        "\t\t\t\"max_sn_token\": 35,\n",
        "\t\t\t\"max_sp_len\": 52, #include start token and end token\n",
        "\t\t\t\"max_sp_token\": 395,\n",
        "\t\t\t\"norm_type\": \"z-score\",\n",
        "\t\t\t\"earlystop_patience\": 20,\n",
        "\t\t\t\"max_pred_len\": 60\n",
        "\t\t\t}\n",
        "\n",
        "\t#Encode the label into interger categories, setting the exclusive category 'cf[\"max_sn_len\"]-1' as the end sign\n",
        "\tle = LabelEncoder()\n",
        "\tle.fit(np.append(np.arange(-cf[\"max_sn_len\"]+3, cf[\"max_sn_len\"]-1), cf[\"max_sn_len\"]-1))\n",
        "\t#le.classes_\n",
        "\n",
        "\t#load corpus\n",
        "\tword_info_df, _, eyemovement_df = load_corpus(cf[\"dataset\"])\n",
        "\n",
        "\treader_list = celer_load_native_speaker()\n",
        "\t#Make list with sentence index\n",
        "\tsn_list = np.unique(word_info_df[word_info_df['list'].isin(reader_list)].sentenceid.values).tolist()\n",
        "\n",
        "\n",
        "\t#Split training&test sets by text or reader, depending on configuration\n",
        "\tif test_mode == 'text':\n",
        "\t\tprint('Start evaluating on new sentences.')\n",
        "\t\tsplit_list = sn_list\n",
        "\telif test_mode == 'subject':\n",
        "\t\tprint('Start evaluating on new readers.')\n",
        "\t\tsplit_list = reader_list\n",
        "\n",
        "\tn_folds = cf[\"n_folds\"]\n",
        "\tkf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
        "\tfold_indx = 0\n",
        "\t#for scanpath generation\n",
        "\tsp_dnn_list = []\n",
        "\tsp_human_list = []\n",
        "\n",
        "\tsent_dict = convert_sent_id(sn_list)\n",
        "\n",
        "\tfor train_idx, test_idx in kf.split(split_list):\n",
        "\t\tloss_dict = {'val_loss':[], 'train_loss':[], 'test_ll':[], 'test_ll_SE':[], 'test_mse_dur':[], 'test_mse_dur_SE':[], 'test_mse_land_pos':[], 'test_mse_land_pos_SE':[], 'central_scasim_dnn':[], 'central_scasim_dnn_SE':[], 'central_scasim_human':[], 'central_scasim_human_SE':[], 'scasim_dnn':[], 'scasim_dnn_SE':[], 'scasim_human':[], 'scasim_human_SE':[], 'uniform_scasim':[], 'uniform_scasim_SE':[], 'uniform_central_scasim':[], 'uniform_central_scasim_SE':[], 'uniform_nll_SE':[], 'uniform_nll':[], 'uniform_mse_dur_SE':[], 'uniform_mse_dur':[], 'uniform_mse_land_pos_SE':[], 'uniform_mse_land_pos':[],\n",
        "\t\t             'ez_reader_scasim':[], 'ez_reader_scasim_SE':[], 'ez_reader_central_scasim':[], 'ez_reader_central_scasim_SE':[], 'ez_reader_mse_dur_SE':[], 'ez_reader_mse_dur':[], 'ez_reader_mse_land_pos_SE':[], 'ez_reader_mse_land_pos':[], 'SWIFT_scasim':[], 'SWIFT_scasim_SE':[], 'SWIFT_central_scasim':[], 'SWIFT_central_scasim_SE':[], 'SWIFT_nll_SE':[], 'SWIFT_nll':[], 'SWIFT_mse_dur_SE':[], 'SWIFT_mse_dur':[], 'SWIFT_mse_land_pos_SE':[], 'SWIFT_mse_land_pos':[]}\n",
        "\t\tlist_train = [split_list[i] for i in train_idx]\n",
        "\t\tlist_test = [split_list[i] for i in test_idx]\n",
        "\n",
        "\t\t# create train validation split for training the models:\n",
        "\t\tkf_val = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
        "\t\tfor train_index, val_index in kf_val.split(list_train):\n",
        "\t\t\t# we only evaluate a single fold\n",
        "\t\t\tbreak\n",
        "\t\tlist_train_net = [list_train[i] for i in train_index]\n",
        "\t\tlist_val_net = [list_train[i] for i in val_index]\n",
        "\n",
        "\t\tif test_mode == 'text':\n",
        "\t\t\tsn_list_train = list_train_net\n",
        "\t\t\tsn_list_val = list_val_net\n",
        "\t\t\tsn_list_test = list_test\n",
        "\t\t\treader_list_train, reader_list_val, reader_list_test = reader_list, reader_list, reader_list\n",
        "\n",
        "\t\telif test_mode == 'subject':\n",
        "\t\t\treader_list_train = list_train_net\n",
        "\t\t\treader_list_val = list_val_net\n",
        "\t\t\treader_list_test = list_test\n",
        "\t\t\tsn_list_train, sn_list_val, sn_list_test = sn_list, sn_list, sn_list\n",
        "\n",
        "\t\t#initialize tokenizer\n",
        "\t\ttokenizer = BertTokenizerFast.from_pretrained(cf['model_pretrained'])\n",
        "\n",
        "\t\tfiltered_sent_dict_train = get_relevant_sent_dict(sent_dict, sn_list_train)\n",
        "\t\tfiltered_sent_dict_val = get_relevant_sent_dict(sent_dict, sn_list_val)\n",
        "\t\tfiltered_sent_dict_test = get_relevant_sent_dict(sent_dict, sn_list_test)\n",
        "\n",
        "\t\t#Preparing batch data\n",
        "\t\tdataset_train = celerdataset(word_info_df, eyemovement_df, cf, reader_list_train, sn_list_train, tokenizer, filtered_sent_dict_train)\n",
        "\t\ttrain_dataloaderr = DataLoader(dataset_train, batch_size = cf[\"batch_size\"], shuffle = True, drop_last=True)\n",
        "\n",
        "\t\tdataset_val = celerdataset(word_info_df, eyemovement_df, cf, reader_list_val, sn_list_val, tokenizer, filtered_sent_dict_val)\n",
        "\t\tval_dataloaderr = DataLoader(dataset_val, batch_size = cf[\"batch_size\"], shuffle = False, drop_last=True)\n",
        "\n",
        "\t\tdataset_test = celerdataset(word_info_df, eyemovement_df, cf, reader_list_test, sn_list_test, tokenizer, filtered_sent_dict_test)\n",
        "\t\ttest_dataloaderr = DataLoader(dataset_test, batch_size = cf[\"batch_size\"], shuffle = False, drop_last=False)\n",
        "\n",
        "\t\t#z-score normalization for gaze features\n",
        "\t\tfix_dur_mean, fix_dur_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sp_fix_dur\", padding_value=0, scale=1000)\n",
        "\t\tlanding_pos_mean, landing_pos_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sp_landing_pos\", padding_value=0)\n",
        "\t\tsn_word_len_mean, sn_word_len_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sn_word_len\")\n",
        "\n",
        "\t\t# load model\n",
        "\t\tdnn = Eyettention(cf)\n",
        "\t\tprint(\"fold_indx\", fold_indx)\n",
        "\n",
        "\t\t#training\n",
        "\t\tepisode = 0\n",
        "\t\toptimizer = Adam(dnn.parameters(), lr=cf[\"lr\"])\n",
        "\t\tdnn.train()\n",
        "\t\tdnn.to(device)\n",
        "\t\tav_score = deque(maxlen=100)\n",
        "\t\tav_location_score = deque(maxlen=100)\n",
        "\t\tav_duration_score = deque(maxlen=100)\n",
        "\t\tav_land_pos_score = deque(maxlen=100)\n",
        "\t\told_score = 1e10\n",
        "\t\tsave_ep_couter = 0\n",
        "\t\tprint('Start training')\n",
        "\t\tfor episode_i in range(episode, cf[\"n_epochs\"]+1):\n",
        "\t\t\tdnn.train()\n",
        "\t\t\tprint('episode:', episode_i)\n",
        "\t\t\tcounter = 0\n",
        "\t\t\tfor batchh in train_dataloaderr:\n",
        "\t\t\t\tcounter += 1\n",
        "\t\t\t\tbatchh.keys()\n",
        "\t\t\t\tsn_ids = batchh[\"sn_ids\"].to(device)\n",
        "\t\t\t\tsn_input_ids = batchh[\"sn_input_ids\"].to(device)\n",
        "\t\t\t\tsn_attention_mask = batchh[\"sn_attention_mask\"].to(device)\n",
        "\t\t\t\tword_ids_sn = batchh[\"word_ids_sn\"].to(device)\n",
        "\t\t\t\tsn_word_len = batchh[\"sn_word_len\"].to(device)\n",
        "\n",
        "\t\t\t\tsp_input_ids = batchh[\"sp_input_ids\"].to(device)\n",
        "\t\t\t\tsp_attention_mask = batchh[\"sp_attention_mask\"].to(device)\n",
        "\t\t\t\tword_ids_sp = batchh[\"word_ids_sp\"].to(device)\n",
        "\n",
        "\t\t\t\tsp_pos = batchh[\"sp_pos\"].to(device)\n",
        "\t\t\t\tsp_landing_pos = batchh[\"sp_landing_pos\"].to(device) # [256, 40]\n",
        "\t\t\t\tsp_fix_dur = (batchh[\"sp_fix_dur\"]/1000).to(device) # [256, 40]\n",
        "\n",
        "\t\t\t\t# normalize gaze features (z-score normalisation)\n",
        "\t\t\t\tmask = ~torch.eq(sp_fix_dur, 0)\n",
        "\t\t\t\tsp_fix_dur = (sp_fix_dur-fix_dur_mean)/fix_dur_std * mask\n",
        "\t\t\t\tsp_fix_dur = torch.nan_to_num(sp_fix_dur) # [256, 40]\n",
        "\t\t\t\tsp_landing_pos = (sp_landing_pos - landing_pos_mean)/landing_pos_std * mask\n",
        "\t\t\t\tsp_landing_pos = torch.nan_to_num(sp_landing_pos)\n",
        "\t\t\t\tsn_word_len = (sn_word_len - sn_word_len_mean)/sn_word_len_std\n",
        "\t\t\t\tsn_word_len = torch.nan_to_num(sn_word_len)\n",
        "\t\t\t\tsub_id = batchh[\"sub_id\"].to(device)\n",
        "\n",
        "\t\t\t\t# zero old gradients\n",
        "\t\t\t\toptimizer.zero_grad()\n",
        "\t\t\t\t# predict output with DNN\n",
        "\t\t\t\tlocation_preds, duration_preds, landing_pos_preds, atten_weights = dnn(sn_emd=sn_input_ids,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_mask=sn_attention_mask,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_emd=sp_input_ids,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_pos=sp_pos,\n",
        "\t\t\t\t\t\t\t\t\t\t\tword_ids_sn=word_ids_sn,\n",
        "\t\t\t\t\t\t\t\t\t\t\tword_ids_sp=word_ids_sp,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_fix_dur=sp_fix_dur,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_landing_pos=sp_landing_pos,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_word_len = sn_word_len,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_word_freq= None,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_pred = None)#[batch, step, dec_o_dim]\n",
        "\n",
        "\t\t\t\tlocation_preds = location_preds.permute(0,2,1)              #[batch, dec_o_dim, step]\n",
        "\n",
        "\t\t\t\t#prepare label and mask\n",
        "\t\t\t\t# Compute loss for fixation locations\n",
        "\t\t\t\tpad_mask, label = load_label(sp_pos, cf, le, device)\n",
        "\t\t\t\tloss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\t\t\t\tbatch_location_error = torch.mean(torch.masked_select(loss(location_preds, label), ~pad_mask))\n",
        "\n",
        "\t\t\t\t# Compute loss for fixation durations\n",
        "\t\t\t\tduration_labels = sp_fix_dur[:, :51] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\tduration_preds = duration_preds.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\tdur_loss = nn.MSELoss(reduction=\"none\")\n",
        "\t\t\t\tbatch_duration_error = torch.mean(dur_loss(duration_preds, duration_labels))\n",
        "\n",
        "\t\t\t\t# Compute loss for landing position\n",
        "\t\t\t\tlanding_pos_labels = sp_landing_pos[:, :51] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\tlanding_pos_preds = landing_pos_preds.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\tland_pos_loss = nn.MSELoss(reduction=\"none\")\n",
        "\t\t\t\tbatch_land_pos_error = torch.mean(land_pos_loss(landing_pos_preds, landing_pos_labels))\n",
        "\n",
        "\t\t\t\t# Combined loss for both location and duration\n",
        "\t\t\t\tbatch_error = batch_location_error +  batch_duration_error + batch_land_pos_error\n",
        "\n",
        "\t\t\t\t# backpropagate loss\n",
        "\t\t\t\tbatch_error.backward()\n",
        "\t\t\t\t# clip gradients\n",
        "\t\t\t\tgradient_clipping(dnn, cf[\"max_grad_norm\"])\n",
        "\n",
        "\t\t\t\t#learn\n",
        "\t\t\t\toptimizer.step()\n",
        "\t\t\t\tav_location_score.append(batch_location_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_duration_score.append(batch_duration_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_land_pos_score.append(batch_land_pos_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_score.append(batch_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tprint('counter:',counter)\n",
        "\t\t\t\tprint('\\rSample {}\\tLocation Loss: {:.10f}\\tDuration Loss: {:.10f}\\tLanding position Loss: {:.10f}'.format(\n",
        "          counter, np.mean(av_location_score), np.mean(av_duration_score), np.mean(av_land_pos_score)), end=\" \")\n",
        "\t\t\tloss_dict['train_loss'].append(np.mean(av_score))\n",
        "\n",
        "\t\t\tlocation_val_loss = []\n",
        "\t\t\tduration_val_loss = []\n",
        "\t\t\tland_pos_val_loss = []\n",
        "\t\t\tval_loss = []\n",
        "\t\t\tdnn.eval()\n",
        "\t\t\tfor batchh in val_dataloaderr:\n",
        "\t\t\t\twith torch.no_grad():\n",
        "\t\t\t\t\tsn_ids_val = batchh[\"sn_ids\"].to(device)\n",
        "\t\t\t\t\tsn_input_ids_val = batchh[\"sn_input_ids\"].to(device)\n",
        "\t\t\t\t\tsn_attention_mask_val = batchh[\"sn_attention_mask\"].to(device)\n",
        "\t\t\t\t\tword_ids_sn_val = batchh[\"word_ids_sn\"].to(device)\n",
        "\t\t\t\t\tsn_word_len_val = batchh[\"sn_word_len\"].to(device)\n",
        "\n",
        "\t\t\t\t\tsp_input_ids_val = batchh[\"sp_input_ids\"].to(device)\n",
        "\t\t\t\t\tsp_attention_mask_val = batchh[\"sp_attention_mask\"].to(device)\n",
        "\t\t\t\t\tword_ids_sp_val = batchh[\"word_ids_sp\"].to(device)\n",
        "\n",
        "\t\t\t\t\tsp_pos_val = batchh[\"sp_pos\"].to(device)\n",
        "\t\t\t\t\tsp_landing_pos_val = batchh[\"sp_landing_pos\"].to(device)\n",
        "\t\t\t\t\tsp_fix_dur_val = (batchh[\"sp_fix_dur\"]/1000).to(device)\n",
        "\n",
        "\t\t\t\t\t#normalize gaze features\n",
        "\t\t\t\t\tmask = ~torch.eq(sp_fix_dur_val, 0)\n",
        "\t\t\t\t\tsp_fix_dur_val = (sp_fix_dur_val-fix_dur_mean)/fix_dur_std * mask\n",
        "\t\t\t\t\tsp_landing_pos_val = (sp_landing_pos_val - landing_pos_mean)/landing_pos_std * mask\n",
        "\t\t\t\t\tsp_fix_dur_val = torch.nan_to_num(sp_fix_dur_val)\n",
        "\t\t\t\t\tsp_landing_pos_val = torch.nan_to_num(sp_landing_pos_val)\n",
        "\t\t\t\t\tsn_word_len_val = (sn_word_len_val - sn_word_len_mean)/sn_word_len_std\n",
        "\t\t\t\t\tsn_word_len_val = torch.nan_to_num(sn_word_len_val)\n",
        "\t\t\t\t\tsub_id_val = batchh[\"sub_id\"].to(device)\n",
        "\n",
        "\t\t\t\t\tlocation_preds_val, duration_preds_val, landing_pos_preds_val, atten_weights_val = dnn(sn_emd=sn_input_ids_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_mask=sn_attention_mask_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_emd=sp_input_ids_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_pos=sp_pos_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sn=word_ids_sn_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sp=word_ids_sp_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_fix_dur=sp_fix_dur_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_landing_pos=sp_landing_pos_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_word_len = sn_word_len_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_word_freq= None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t      sn_pred = None)#[batch, step, dec_o_dim]\n",
        "\t\t\t\t\tlocation_preds_val = location_preds_val.permute(0,2,1)              #[batch, dec_o_dim, step\n",
        "\n",
        "\t\t\t\t\t# Compute location prediction error\n",
        "\t\t\t\t\tloss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\t\t\t\t\tpad_mask_val, label_val = load_label(sp_pos_val, cf, le, device)\n",
        "\t\t\t\t\tlocation_error_val = torch.mean(torch.masked_select(loss(location_preds_val, label_val), ~pad_mask_val))\n",
        "\t\t\t\t\tlocation_val_loss.append(location_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\t# Compute duration prediction error\n",
        "\t\t\t\t\tduration_labels_val = sp_fix_dur_val[:, :51] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\t\tduration_preds_val = duration_preds_val.squeeze(-1)\n",
        "\t\t\t\t\tdur_loss = nn.MSELoss(reduction=\"none\")\n",
        "\t\t\t\t\tduration_error_val = torch.mean(dur_loss(duration_preds_val, duration_labels_val))\n",
        "\t\t\t\t\tduration_val_loss.append(duration_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\t# Compute loss for landing position\n",
        "\t\t\t\t\tlanding_pos_labels_val = sp_landing_pos_val[:, :51] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\t\tlanding_pos_preds_val = landing_pos_preds_val.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\t\tland_pos_error_val = torch.mean(land_pos_loss(landing_pos_preds_val, landing_pos_labels_val))\n",
        "\t\t\t\t\tland_pos_val_loss.append(land_pos_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\tcombined_loss = location_error_val + duration_error_val + land_pos_error_val\n",
        "\t\t\t\t\tval_loss.append(combined_loss.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\tprint('\\nValidation loss for locations {} \\n'.format(np.mean(location_val_loss)))\n",
        "\t\t\tprint('\\nValidation loss for duration {} \\n'.format(np.mean(duration_val_loss)))\n",
        "\t\t\tprint('\\nValidation loss for landing position {} \\n'.format(np.mean(land_pos_val_loss)))\n",
        "\t\t\tloss_dict['val_loss'].append(np.mean(val_loss))\n",
        "\n",
        "\t\t\tif np.mean(val_loss) < old_score:\n",
        "\t\t\t\t# save model if val loss is smallest\n",
        "\t\t\t\ttorch.save(dnn.state_dict(), '{}/CELER_Eyettention_new_reader_{}.pth'.format(save_data_folder, fold_indx))\n",
        "\t\t\t\told_score = np.mean(val_loss)\n",
        "\t\t\t\tprint('\\nsaved model state dict\\n')\n",
        "\t\t\t\tsave_ep_couter = episode_i\n",
        "\t\t\telse:\n",
        "\t\t\t\t#early stopping\n",
        "\t\t\t\tif episode_i - save_ep_couter >= cf[\"earlystop_patience\"]:\n",
        "\t\t\t\t\tbreak\n",
        "\t\tfold_indx += 1\n",
        "\n",
        "\t\t#evaluation\n",
        "\t\tdnn.eval()\n",
        "\t\tres_llh=[]\n",
        "\t\tres_mse_dur = []\n",
        "\t\tres_mse_land_pos = []\n",
        "\t\tres_central_scasim_human = []\n",
        "\t\tres_central_scasim_dnn = []\n",
        "\t\tres_scasim_human = []\n",
        "\t\tres_scasim_dnn = []\n",
        "\t\tuniform_central_scasim_scores = []\n",
        "\t\tuniform_scasim_scores = []\n",
        "\t\tuniform_nll_scores = []\n",
        "\t\tuniform_mse_dur_scores = []\n",
        "\t\tuniform_mse_land_pos_scores = []\n",
        "\t\tez_reader_central_scasim_scores = []\n",
        "\t\tez_reader_scasim_scores = []\n",
        "\t\tez_reader_nll_scores = []\n",
        "\t\tez_reader_mse_dur_scores = []\n",
        "\t\tez_reader_mse_land_pos_scores = []\n",
        "\t\tswift_central_scasim_scores = []\n",
        "\t\tswift_scasim_scores = []\n",
        "\t\tswift_nll_scores = []\n",
        "\t\tswift_mse_dur_scores = []\n",
        "\t\tswift_mse_land_pos_scores = []\n",
        "\t\tdnn.load_state_dict(torch.load(os.path.join(save_data_folder, f'CELER_Eyettention_new_reader_{fold_indx}.pth'), map_location='cpu'))\n",
        "\t\tdnn.to(device)\n",
        "\t\tbatch_indx = 0\n",
        "\t\tfor batchh in test_dataloaderr:\n",
        "\t\t\twith torch.no_grad():\n",
        "\t\t\t\tsn_ids_test = batchh[\"sn_ids\"].to(device)\n",
        "\t\t\t\tsn_input_ids_test = batchh[\"sn_input_ids\"].to(device)\n",
        "\t\t\t\tsn_attention_mask_test = batchh[\"sn_attention_mask\"].to(device)\n",
        "\t\t\t\tword_ids_sn_test = batchh[\"word_ids_sn\"].to(device)\n",
        "\t\t\t\tsn_word_len_test = batchh[\"sn_word_len\"].to(device)\n",
        "\n",
        "\t\t\t\tsp_input_ids_test = batchh[\"sp_input_ids\"].to(device)\n",
        "\t\t\t\tsp_attention_mask_test = batchh[\"sp_attention_mask\"].to(device)\n",
        "\t\t\t\tword_ids_sp_test = batchh[\"word_ids_sp\"].to(device)\n",
        "\n",
        "\t\t\t\tsp_pos_test = batchh[\"sp_pos\"].to(device) # 28: '<Sep>', 29: '<'Pad'>'\n",
        "\t\t\t\tsp_landing_pos_test = batchh[\"sp_landing_pos\"].to(device)\n",
        "\t\t\t\tsp_fix_dur_test = (batchh[\"sp_fix_dur\"]/1000).to(device)\n",
        "\n",
        "\t\t\t\t#normalize gaze features\n",
        "\t\t\t\tmask = ~torch.eq(sp_fix_dur_test, 0)\n",
        "\t\t\t\tsp_fix_dur_test = (sp_fix_dur_test-fix_dur_mean)/fix_dur_std * mask\n",
        "\t\t\t\tsp_landing_pos_test = (sp_landing_pos_test - landing_pos_mean)/landing_pos_std * mask\n",
        "\t\t\t\tsp_fix_dur_test = torch.nan_to_num(sp_fix_dur_test)\n",
        "\t\t\t\tsp_landing_pos_test = torch.nan_to_num(sp_landing_pos_test)\n",
        "\t\t\t\tsn_word_len_test = (sn_word_len_test - sn_word_len_mean)/sn_word_len_std\n",
        "\t\t\t\tsn_word_len_test = torch.nan_to_num(sn_word_len_test)\n",
        "\n",
        "\t\t\t\tlocation_preds_test, duration_preds_test, landing_pos_preds_test, atten_weights_test = dnn(sn_emd=sn_input_ids_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_mask=sn_attention_mask_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_emd=sp_input_ids_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_pos=sp_pos_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sn=word_ids_sn_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sp=word_ids_sp_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_fix_dur=sp_fix_dur_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_landing_pos=sp_landing_pos_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_word_len = sn_word_len_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_pred=None,\n",
        "                            sn_word_freq=None) #[batch, step, dec_o_dim]\n",
        "\n",
        "\n",
        "\t\t\t\t########## Evaluate location predictions ##########\n",
        "\t\t\t\tm = nn.Softmax(dim=2)\n",
        "\t\t\t\tlocation_preds_test = m(location_preds_test).detach().to('cpu').numpy()\n",
        "\t\t\t\t#prepare label and mask\n",
        "\t\t\t\tpad_mask_test, label_test = load_label(sp_pos_test, cf, le, 'cpu')\n",
        "\t\t\t\t#compute log likelihood for the batch samples\n",
        "\t\t\t\tres_batch = eval_log_llh(location_preds_test, label_test, pad_mask_test)\n",
        "\t\t\t\tres_llh.append(np.array(res_batch))\n",
        "\n",
        "\t\t\t\tuniform_output = construct_uniform_tensor(location_preds_test)\n",
        "\t\t\t\tuniform_nll = eval_log_llh(uniform_output, label_test, pad_mask_test)\n",
        "\t\t\t\tuniform_nll_scores.append(np.array(uniform_nll))\n",
        "\t\t\t\tprint(\"Uniform_nll\", np.mean(uniform_nll), uniform_nll)\n",
        "\n",
        "\t\t\t\tprint(\"######### Eyettention 2.0 model evaluation ##########\")\n",
        "\t\t\t\tduration_preds_test = duration_preds_test.squeeze(-1)\n",
        "\t\t\t\tduration_labels_test = sp_fix_dur_test[:, :51]\n",
        "\t\t\t\ttest_mask = mask[:, :51]\n",
        "\t\t\t\tmse_dur = eval_mse(duration_preds_test, duration_labels_test, test_mask)\n",
        "\t\t\t\tprint(\"MSE for durations\", np.mean(mse_dur))\n",
        "\t\t\t\tres_mse_dur.append(np.array(mse_dur))\n",
        "\n",
        "\t\t\t\tlanding_pos_preds_test = landing_pos_preds_test.squeeze(-1)\n",
        "\t\t\t\tlanding_pos_labels_test = sp_landing_pos_test[:, :51]\n",
        "\t\t\t\tmse_landing_pos = eval_mse(landing_pos_preds_test, landing_pos_labels_test, test_mask)\n",
        "\t\t\t\tprint(\"MSE for landing positions\", np.mean(mse_landing_pos))\n",
        "\t\t\t\tres_mse_land_pos.append(np.array(mse_landing_pos))\n",
        "\n",
        "\t\t\t\tif bool(scanpath_gen_flag) == True:\n",
        "\t\t\t\t\tsn_len = (torch.max(torch.nan_to_num(word_ids_sn_test), dim=1)[0]+1-2).detach().to('cpu').numpy()\n",
        "\t\t\t\t\t# compute the scan path generated from the model when the first CLS token is given\n",
        "\t\t\t\t\tsp_dnn, _, dur_dnn, land_pos_dnn = dnn.scanpath_generation(sn_emd=sn_input_ids_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sn_mask=sn_attention_mask_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t word_ids_sn=word_ids_sn_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sn_word_len = sn_word_len_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t le=le,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sn_word_freq=None,\n",
        "                             sn_pred=None,\n",
        "                             sp_fix_dur=sp_fix_dur_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sp_landing_pos = sp_landing_pos_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t max_pred_len=cf['max_pred_len'])\n",
        "\n",
        "\n",
        "\t\t\t\t\tsp_dnn, sp_human = prepare_scanpath(sp_dnn.detach().to('cpu').numpy(),\n",
        "                                              dur_dnn.detach().to('cpu').numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tland_pos_dnn.detach().to('cpu').numpy(), sn_len, sp_pos_test,\n",
        "                                              sp_fix_dur_test, sp_landing_pos_test, cf, sn_ids_test, fix_dur_mean, fix_dur_std, landing_pos_mean, landing_pos_std)\n",
        "\n",
        "\t\t\t\t\tsp_dnn_list.extend(sp_dnn)\n",
        "\t\t\t\t\tsp_human_list.extend(sp_human)\n",
        "\n",
        "\t\t\t\t\tsp_dnn = filter_sp(sp_dnn)\n",
        "\t\t\t\t\tsp_human = filter_sp(sp_human)\n",
        "\n",
        "\n",
        "\t\t\t\t\tif len(sp_dnn[\"sent_id\"]) != 0:\n",
        "\t\t\t\t\t\t# evaluate only on sent that were read by multiple subjects\n",
        "\t\t\t\t\t\tsp_dnn = convert_sp_to_lists(sp_dnn)\n",
        "\t\t\t\t\t\tsp_human = convert_sp_to_lists(sp_human)\n",
        "\t\t\t\t\t\tsp_human = modify_landing_pos(sp_human.copy())\n",
        "\t\t\t\t\t\tsp_dnn = modify_landing_pos(sp_dnn.copy())\n",
        "\t\t\t\t\t\trandom_sp = sample_random_sp(\"CELER\", sp_human, 'data_splits/CELER_sent_dict.txt')\n",
        "\t\t\t\t\t\trandom_sp = convert_sp_to_lists(random_sp)\n",
        "\t\t\t\t\t\trandom_sp = modify_landing_pos(random_sp.copy())\n",
        "\n",
        "\n",
        "\t\t\t\t\t\tprint(\"######### Eyettention model evaluation ##########\")\n",
        "\t\t\t\t\t\tscasim_scores_dnn = compute_scasim(sp_dnn, sp_human)\n",
        "\t\t\t\t\t\tres_scasim_dnn.append(scasim_scores_dnn)\n",
        "\t\t\t\t\t\tprint(\"Mean scasim dnn\", np.mean(scasim_scores_dnn))\n",
        "\t\t\t\t\t\tscasim_scores_human = compute_scasim(sp_human, random_sp)\n",
        "\t\t\t\t\t\tres_scasim_human.append(scasim_scores_human)\n",
        "\t\t\t\t\t\tprint(\"Mean scasim human\", np.mean(scasim_scores_human))\n",
        "\n",
        "\t\t\t\t\t\tcentral_scasim_scores_dnn = compute_central_scasim(\"CELER_most_central_sp.txt\", sp_dnn, 'data_splits/CELER_sent_dict.txt')\n",
        "\t\t\t\t\t\tcentral_scasim_scores_human = compute_central_scasim(\"CELER_most_central_sp.txt\", sp_human, 'data_splits/CELER_sent_dict.txt')\n",
        "\t\t\t\t\t\tres_central_scasim_dnn.append(np.array(central_scasim_scores_dnn))\n",
        "\t\t\t\t\t\tres_central_scasim_human.append(np.array(central_scasim_scores_human))\n",
        "\t\t\t\t\t\tprint(\"Mean central scasim dnn\", np.mean(central_scasim_scores_dnn))\n",
        "\t\t\t\t\t\tprint(\"Mean central scasim human\", np.mean(central_scasim_scores_human))\n",
        "\n",
        "\t\t\t\t\t\tprint(\"######### Uniform baseline model evaluation ##########\")\n",
        "\t\t\t\t\t\tmean_dur_uniform, std_dur_uniform, mean_land_pos_uniform, std_land_pos_uniform = compute_mean_std_uniform(\"drive/MyDrive/baseline/Uniform/CELER_uniform_results.csv\")\n",
        "\t\t\t\t\t\tuniform_central_scasim, uniform_scasim, dur_mse_scores, land_pos_mse_scores = evaluate_uniform_model(\"CELER\", sp_human, landing_pos_mean, landing_pos_std, fix_dur_mean, fix_dur_std, mean_land_pos_uniform, std_land_pos_uniform, mean_dur_uniform, std_dur_uniform)\n",
        "\t\t\t\t\t\tuniform_central_scasim_scores.append(np.array(uniform_central_scasim))\n",
        "\t\t\t\t\t\tuniform_scasim_scores.append(np.array(uniform_scasim))\n",
        "\t\t\t\t\t\tuniform_mse_dur_scores.append(np.array(dur_mse_scores))\n",
        "\t\t\t\t\t\tuniform_mse_land_pos_scores.append(np.array(land_pos_mse_scores))\n",
        "\t\t\t\t\t\tprint(\"Uniform mean central Scasim score:\", np.mean(uniform_central_scasim))\n",
        "\t\t\t\t\t\tprint(\"Uniform mean Scasim score:\", np.mean(uniform_scasim))\n",
        "\t\t\t\t\t\tprint(\"MSE for uniform durations\", np.mean(dur_mse_scores))\n",
        "\t\t\t\t\t\tprint(\"MSE for uniform landing pos\", np.mean(land_pos_mse_scores))\n",
        "\n",
        "\t\t\t\t\t\tprint(\"######### E-Z Reader model evaluation ##########\")\n",
        "\t\t\t\t\t\tmean_dur_ez_reader, std_dur_ez_reader, mean_land_pos_ez_reader, std_land_pos_ez_reader = compute_mean_std_ez_reader(\"drive/MyDrive/baseline/CELERSimulationResultsNew.txt\")\t\t\t\t#\t\tcentral_scasim_ez_reader, scasim_ez_reader, dur_mse_ez_reader, land_pos_mse_ez_reader = evaluate_ez_reader(\"CELER\", \"drive/MyDrive/baseline/CELERSimulationResultsNew.txt\", sp_human, landing_pos_mean, landing_pos_std, fix_dur_mean, fix_dur_std, mean_land_pos_ez_reader, std_land_pos_ez_reader, mean_dur_ez_reader, std_dur_ez_reader)\n",
        "\t\t\t\t\t\tez_reader_central_scasim_scores.append(np.array(central_scasim_ez_reader))\n",
        "\t\t\t\t\t\tprint(\"Central scasim E-Z Reader\", np.mean(central_scasim_ez_reader))\n",
        "\t\t\t\t\t\tez_reader_scasim_scores.append(np.array(scasim_ez_reader))\n",
        "\t\t\t\t\t\tprint(\"Mean scasim score E-Z Reader\", np.mean(scasim_ez_reader))\n",
        "\t\t\t\t\t\tez_reader_mse_dur_scores.append(np.array(dur_mse_ez_reader))\n",
        "\t\t\t\t\t\tprint(\"MSE for durations E-Z Reader\", np.mean(dur_mse_ez_reader))\n",
        "\t\t\t\t\t\tez_reader_mse_land_pos_scores.append(np.array(land_pos_mse_ez_reader))\n",
        "\t\t\t\t\t\tprint(\"MSE for landing pos E-Z Reader\", np.mean(land_pos_mse_ez_reader))\n",
        "\n",
        "\t\t\t\t\t\tprint(\"######### SWIFT model evaluation ##########\")\n",
        "\t\t\t\t\t\tmean_dur_swift, std_dur_swift, mean_land_pos_swift, std_land_pos_swift = compute_mean_std_swift()\n",
        "\t\t\t\t\t\tcentral_scasim_swift, scasim_swift, dur_mse_swift, land_pos_mse_swift = evaluate_swift(\"celer\", sp_human, landing_pos_mean, landing_pos_std, fix_dur_mean, fix_dur_std, mean_land_pos_swift, std_land_pos_swift, mean_dur_swift, std_dur_swift)\n",
        "\t\t\t\t\t\tswift_central_scasim_scores.append(np.array(central_scasim_swift))\n",
        "\t\t\t\t\t\tprint(\"Central scasim SWIFT\", np.mean(central_scasim_swift))\n",
        "\t\t\t\t\t\tswift_scasim_scores.append(np.array(scasim_swift))\n",
        "\t\t\t\t\t\tprint(\"Mean scasim score SWIFT\", np.mean(scasim_swift))\n",
        "\t\t\t\t\t\tswift_mse_dur_scores.append(np.array(dur_mse_swift))\n",
        "\t\t\t\t\t\tprint(\"MSE for durations SWIFT\", np.mean(dur_mse_swift))\n",
        "\t\t\t\t\t\tswift_mse_land_pos_scores.append(np.array(land_pos_mse_swift))\n",
        "\t\t\t\t\t\tprint(\"MSE for landing pos SWIFT\", np.mean(land_pos_mse_swift))\n",
        "\t\t\t\t\t\tswift_nll = evaluate_swift_nll(\"baseline/swift/SWIFT_NLL.xlsx\", sp_human)\n",
        "\t\t\t\t\t\tswift_nll_scores.append(np.array(swift_nll))\n",
        "\t\t\t\t\t\tif len(swift_nll) != 0:\n",
        "\t\t\t\t\t\t\tprint(\"NLL SWIFT\", np.mean(swift_nll))\n",
        "\n",
        "\t\t\t\tbatch_indx +=1\n",
        "\n",
        "\t\tres_llh = np.concatenate(res_llh).ravel()\n",
        "\t\tloss_dict['test_ll'].append(res_llh)\n",
        "\t\tres_mse_dur = np.concatenate(res_mse_dur).ravel()\n",
        "\t\tloss_dict['test_mse_dur'].append(res_mse_dur)\n",
        "\t\tres_mse_land_pos = np.concatenate(res_mse_land_pos).ravel()\n",
        "\t\tloss_dict['test_mse_land_pos'].append(res_mse_land_pos)\n",
        "\n",
        "\t\tres_central_scasim_dnn = np.concatenate(res_central_scasim_dnn).ravel()\n",
        "\t\tloss_dict['central_scasim_dnn'].append(res_central_scasim_dnn)\n",
        "\t\tres_central_scasim_human = np.concatenate(res_central_scasim_human).ravel()\n",
        "\t\tloss_dict['central_scasim_human'].append(res_central_scasim_human)\n",
        "\t\tres_scasim_dnn = np.concatenate(res_scasim_dnn).ravel()\n",
        "\t\tloss_dict['scasim_dnn'].append(res_scasim_dnn)\n",
        "\t\tres_scasim_human = np.concatenate(res_scasim_human).ravel()\n",
        "\t\tloss_dict['scasim_human'].append(res_scasim_human)\n",
        "\n",
        "\t\tloss_dict['fix_dur_mean'] = fix_dur_mean\n",
        "\t\tloss_dict['fix_dur_std'] = fix_dur_std\n",
        "\t\tloss_dict['landing_pos_mean'] = landing_pos_mean\n",
        "\t\tloss_dict['landing_pos_std'] = landing_pos_std\n",
        "\t\tloss_dict['sn_word_len_mean'] = sn_word_len_mean\n",
        "\t\tloss_dict['sn_word_len_std'] = sn_word_len_std\n",
        "\n",
        "\t\tuniform_central_scasim_scores = np.concatenate(uniform_central_scasim_scores).ravel()\n",
        "\t\tloss_dict['uniform_central_scasim'].append(uniform_central_scasim_scores)\n",
        "\t\tuniform_scasim_scores = np.concatenate(uniform_scasim_scores).ravel()\n",
        "\t\tloss_dict['uniform_scasim'].append(uniform_scasim_scores)\n",
        "\n",
        "\t\tuniform_mse_dur_scores = np.concatenate(uniform_mse_dur_scores).ravel()\n",
        "\t\tloss_dict['uniform_mse_dur'].append(uniform_mse_dur_scores)\n",
        "\t\tuniform_mse_land_pos_scores = np.concatenate(uniform_mse_land_pos_scores).ravel()\n",
        "\t\tloss_dict['uniform_mse_land_pos'].append(uniform_mse_land_pos_scores)\n",
        "\t\tuniform_nll_scores = np.concatenate(uniform_nll_scores).ravel()\n",
        "\t\tloss_dict['uniform_nll'].append(uniform_nll_scores)\n",
        "\n",
        "\t\tswift_mse_dur_scores = np.concatenate(swift_mse_dur_scores).ravel()\n",
        "\t\tloss_dict['SWIFT_mse_dur'].append(swift_mse_dur_scores)\n",
        "\t\tswift_mse_land_pos_scores = np.concatenate(swift_mse_land_pos_scores).ravel()\n",
        "\t\tloss_dict['SWIFT_mse_land_pos'].append(swift_mse_land_pos_scores)\n",
        "\t\tswift_nll_scores = np.concatenate(swift_nll_scores).ravel()\n",
        "\t\tloss_dict['SWIFT_nll'].append(swift_nll_scores)\n",
        "\t\tswift_central_scasim_scores = np.concatenate(swift_central_scasim_scores).ravel()\n",
        "\t\tloss_dict['SWIFT_central_scasim'].append(swift_central_scasim_scores)\n",
        "\t\tswift_scasim_scores = np.concatenate(swift_scasim_scores).ravel()\n",
        "\t\tloss_dict['SWIFT_scasim'].append(swift_scasim_scores)\n",
        "\n",
        "\n",
        "\t\tez_reader_central_scasim_scores = np.concatenate(ez_reader_central_scasim_scores).ravel()\n",
        "\t\tloss_dict['ez_reader_central_scasim'].append(ez_reader_central_scasim_scores)\n",
        "\t\tez_reader_scasim_scores = np.concatenate(ez_reader_scasim_scores).ravel()\n",
        "\t\tloss_dict['ez_reader_scasim'].append(ez_reader_scasim_scores)\n",
        "\n",
        "\t\tez_reader_mse_dur_scores = np.concatenate(ez_reader_mse_dur_scores).ravel()\n",
        "\t\tloss_dict['ez_reader_mse_dur'].append(ez_reader_mse_dur_scores)\n",
        "\t\tez_reader_mse_land_pos_scores = np.concatenate(ez_reader_mse_land_pos_scores).ravel()\n",
        "\t\tloss_dict['ez_reader_mse_land_pos'].append(ez_reader_mse_land_pos_scores)\n",
        "\n",
        "\t\tprint('Test likelihood is {}'.format(np.mean(res_llh)))\n",
        "\t\tloss_dict['test_ll_SE'].append(np.std(res_llh)/ np.sqrt(len(res_llh)))\n",
        "\t\tprint(\"Standard error for NLL\", np.std(res_llh)/ np.sqrt(len(res_llh)))\n",
        "\n",
        "\t\tprint('Test MSE for durations is {}'.format(np.mean(res_mse_dur)))\n",
        "\t\tloss_dict['test_mse_dur_SE'].append(np.std(res_mse_dur)/ np.sqrt(len(res_mse_dur)))\n",
        "\t\tprint(\"Standard error for MSE dur\", np.std(res_mse_dur) / np.sqrt(len(res_mse_dur)))\n",
        "\n",
        "\t\tprint('Test MSE for landing positions is {}'.format(np.mean(res_mse_land_pos)))\n",
        "\t\tloss_dict['test_mse_land_pos_SE'].append(np.std(res_mse_land_pos)/ np.sqrt(len(res_mse_land_pos)))\n",
        "\t\tprint(\"Standard error for MSE land pos\", np.std(res_mse_land_pos) / np.sqrt(len(res_mse_land_pos)))\n",
        "\n",
        "\t\tprint(\"Central Scasim dnn\", np.mean(loss_dict['central_scasim_dnn']))\n",
        "\t\tloss_dict['central_scasim_dnn_SE'].append(np.std(res_central_scasim_dnn)/ np.sqrt(len(res_central_scasim_dnn)))\n",
        "\t\tprint(\"Standard error for Central scasim DNN\", np.std(res_central_scasim_dnn) / np.sqrt(len(res_central_scasim_dnn)))\n",
        "\n",
        "\t\tprint(\"Central Scasim human\", np.mean(loss_dict['central_scasim_human']))\n",
        "\t\tloss_dict['central_scasim_human_SE'].append(np.std(res_central_scasim_human)/ np.sqrt(len(res_central_scasim_human)))\n",
        "\t\tprint(\"Standard error for Central scasim human\", np.std(res_central_scasim_human) / np.sqrt(len(res_central_scasim_human)))\n",
        "\n",
        "\t\tprint(\"Scasim dnn\", np.mean(loss_dict['scasim_dnn']))\n",
        "\t\tloss_dict['scasim_dnn_SE'].append(np.std(res_scasim_dnn)/ np.sqrt(len(res_scasim_dnn)))\n",
        "\t\tprint(\"Standard error for scasim dnn\", np.std(res_scasim_dnn) / np.sqrt(len(res_scasim_dnn)))\n",
        "\n",
        "\t\tprint(\"Scasim human\", np.mean(loss_dict['scasim_human']))\n",
        "\t\tloss_dict['scasim_human_SE'].append(np.std(res_scasim_human)/ np.sqrt(len(res_scasim_human)))\n",
        "\t\tprint(\"Standard error for scasim human\", np.std(res_scasim_human) / np.sqrt(len(res_scasim_human)))\n",
        "\n",
        "\t\tprint(\"Uniform central scasim\", np.mean(loss_dict['uniform_central_scasim']))\n",
        "\t\tloss_dict['uniform_central_scasim_SE'].append(np.std(uniform_central_scasim_scores)/ np.sqrt(len(uniform_central_scasim_scores)))\n",
        "\t\tprint(\"Standard error for uniform central scasim\", np.std(uniform_central_scasim_scores) / np.sqrt(len(uniform_central_scasim_scores)))\n",
        "\n",
        "\t\tprint(\"Uniform scasim\", np.mean(loss_dict['uniform_scasim']))\n",
        "\t\tloss_dict['uniform_scasim_SE'].append(np.std(uniform_scasim_scores)/ np.sqrt(len(uniform_scasim_scores)))\n",
        "\t\tprint(\"Standard error for uniform scasim\", np.std(uniform_scasim_scores) / np.sqrt(len(uniform_scasim_scores)))\n",
        "\n",
        "\t\tprint(\"Uniform MSE durations\", np.mean(loss_dict['uniform_mse_dur']))\n",
        "\t\tloss_dict['uniform_mse_dur_SE'].append(np.std(dur_mse_scores)/ np.sqrt(len(dur_mse_scores)))\n",
        "\t\tprint(\"Standard error for uniform MSE durations\", np.std(dur_mse_scores) / np.sqrt(len(dur_mse_scores)))\n",
        "\n",
        "\t\tprint(\"Uniform MSE landing pos\", np.mean(loss_dict['uniform_mse_land_pos']))\n",
        "\t\tloss_dict['uniform_mse_land_pos_SE'].append(np.std(land_pos_mse_scores)/ np.sqrt(len(land_pos_mse_scores)))\n",
        "\t\tprint(\"Standard error for uniform MSE landing pos\", np.std(land_pos_mse_scores) / np.sqrt(len(land_pos_mse_scores)))\n",
        "\n",
        "\t\tprint(\"Uniform NLL\", np.mean(loss_dict['uniform_nll']))\n",
        "\t\tloss_dict['uniform_nll_SE'].append(np.std(uniform_nll_scores)/ np.sqrt(len(uniform_nll_scores)))\n",
        "\t\tprint(\"Standard error for uniform NLL\", np.std(uniform_nll_scores) / np.sqrt(len(uniform_nll_scores)))\n",
        "\n",
        "\t\tprint(\"E-Z Reader central scasim\", np.mean(loss_dict['ez_reader_central_scasim']))\n",
        "\t\tloss_dict['ez_reader_central_scasim_SE'].append(np.std(ez_reader_central_scasim_scores)/ np.sqrt(len(ez_reader_central_scasim_scores)))\n",
        "\t\tprint(\"Standard error for E-Z Reader central scasim\", np.std(ez_reader_central_scasim_scores) / np.sqrt(len(ez_reader_central_scasim_scores)))\n",
        "\n",
        "\t\tprint(\"E-Z Reader scasim\", np.mean(loss_dict['ez_reader_scasim']))\n",
        "\t\tloss_dict['ez_reader_scasim_SE'].append(np.std(ez_reader_scasim_scores)/ np.sqrt(len(ez_reader_scasim_scores)))\n",
        "\t\tprint(\"Standard error for E-Z Reader scasim\", np.std(ez_reader_scasim_scores) / np.sqrt(len(ez_reader_scasim_scores)))\n",
        "\n",
        "\t\tprint(\"E-Z Reader MSE durations\", np.mean(loss_dict['ez_reader_mse_dur']))\n",
        "\t\tloss_dict['ez_reader_mse_dur_SE'].append(np.std(ez_reader_mse_dur_scores)/ np.sqrt(len(ez_reader_mse_dur_scores)))\n",
        "\t\tprint(\"Standard error for E-Z Reader MSE durations\", np.std(ez_reader_mse_dur_scores) / np.sqrt(len(ez_reader_mse_dur_scores)))\n",
        "\n",
        "\t\tprint(\"E-Z Reader MSE landing pos\", np.mean(loss_dict['ez_reader_mse_land_pos']))\n",
        "\t\tloss_dict['ez_reader_mse_land_pos_SE'].append(np.std(ez_reader_mse_land_pos_scores)/ np.sqrt(len(ez_reader_mse_land_pos_scores)))\n",
        "\t\tprint(\"Standard error for E-Z Reader MSE landing pos\", np.std(ez_reader_mse_land_pos_scores) / np.sqrt(len(ez_reader_mse_land_pos_scores)))\n",
        "\n",
        "\t\tprint(\"SWIFT NLL\", np.mean(loss_dict['SWIFT_nll']))\n",
        "\t\tloss_dict['SWIFT_nll_SE'].append(np.std(swift_nll_scores)/ np.sqrt(len(swift_nll_scores)))\n",
        "\t\tprint(\"Standard error for SWIFT NLL\", np.std(swift_nll_scores) / np.sqrt(len(swift_nll_scores)))\n",
        "\n",
        "\t\tprint(\"SWIFT central scasim\", np.mean(loss_dict['SWIFT_central_scasim']))\n",
        "\t\tloss_dict['SWIFT_central_scasim_SE'].append(np.std(swift_central_scasim_scores)/ np.sqrt(len(swift_central_scasim_scores)))\n",
        "\t\tprint(\"Standard error for SWIFT central scasim\", np.std(swift_central_scasim_scores) / np.sqrt(len(swift_central_scasim_scores)))\n",
        "\n",
        "\t\tprint(\"SWIFT scasim\", np.mean(loss_dict['SWIFT_scasim']))\n",
        "\t\tloss_dict['SWIFT_scasim_SE'].append(np.std(swift_scasim_scores)/ np.sqrt(len(swift_scasim_scores)))\n",
        "\t\tprint(\"Standard error for SWIFT scasim\", np.std(swift_scasim_scores) / np.sqrt(len(swift_scasim_scores)))\n",
        "\n",
        "\t\tprint(\"SWIFT MSE durations\", np.mean(loss_dict['SWIFT_mse_dur']))\n",
        "\t\tloss_dict['SWIFT_mse_dur_SE'].append(np.std(swift_mse_dur_scores)/ np.sqrt(len(swift_mse_dur_scores)))\n",
        "\t\tprint(\"Standard error for SWIFT MSE durations\", np.std(swift_mse_dur_scores) / np.sqrt(len(swift_mse_dur_scores)))\n",
        "\n",
        "\t\tprint(\"SWIFT MSE landing pos\", np.mean(loss_dict['SWIFT_mse_land_pos']))\n",
        "\t\tloss_dict['SWIFT_mse_land_pos_SE'].append(np.std(swift_mse_land_pos_scores)/ np.sqrt(len(swift_mse_land_pos_scores)))\n",
        "\t\tprint(\"Standard error for SWIFT MSE landing pos\", np.std(swift_mse_land_pos_scores) / np.sqrt(len(swift_mse_land_pos_scores)))\n",
        "\n",
        "\t\t#save results\n",
        "\t\twith open('{}/res_CELER_{}_eyettention_{}_Fold{}.pickle'.format(save_data_folder, test_mode, atten_type, fold_indx), 'wb') as handle:\n",
        "\t\t\tpickle.dump(loss_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\t\tfold_indx += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Analysing the results\n",
        "test_ll_all_folds = []\n",
        "test_mse_dur_all_folds = []\n",
        "test_mse_land_pos_all_folds = []\n",
        "scasim_dnn_all_folds = []\n",
        "scasim_human_all_folds = []\n",
        "central_scasim_dnn_all_folds = []\n",
        "central_scasim_human_all_folds = []\n",
        "\n",
        "uniform_ll_all_folds = []\n",
        "uniform_mse_dur_all_folds = []\n",
        "uniform_mse_land_pos_all_folds = []\n",
        "uniform_scasim_all_folds = []\n",
        "uniform_central_scasim_all_folds = []\n",
        "\n",
        "ez_reader_mse_dur_all_folds = []\n",
        "ez_reader_mse_land_pos_all_folds = []\n",
        "ez_reader_scasim_all_folds = []\n",
        "ez_reader_central_scasim_all_folds = []\n",
        "\n",
        "fold_index = 0\n",
        "for i in range(5):\n",
        "  with open(f'drive/MyDrive/results/celer/New_Reader/res_CELER_subject_eyettention_local_g_Fold{fold_index}.pickle', 'rb') as original:\n",
        "      reader_results = pickle.load(original)\n",
        "      test_ll_all_folds.extend(reader_results['test_ll'][0])\n",
        "      test_mse_dur_all_folds.extend(reader_results['test_mse_dur'][0])\n",
        "      test_mse_land_pos_all_folds.extend(reader_results['test_mse_land_pos'][0])\n",
        "      scasim_dnn_all_folds.extend(reader_results['scasim_dnn'][0])\n",
        "      scasim_human_all_folds.extend(reader_results['scasim_human'][0])\n",
        "      central_scasim_dnn_all_folds.extend(reader_results['central_scasim_dnn'][0])\n",
        "      central_scasim_human_all_folds.extend(reader_results['central_scasim_human'][0])\n",
        "\n",
        "      uniform_ll_all_folds.extend(reader_results['uniform_nll'][0])\n",
        "      uniform_mse_dur_all_folds.extend(reader_results['uniform_mse_dur'][0])\n",
        "      uniform_mse_land_pos_all_folds.extend(reader_results['uniform_mse_land_pos'][0])\n",
        "      uniform_scasim_all_folds.extend(reader_results['uniform_scasim'][0])\n",
        "      uniform_central_scasim_all_folds.extend(reader_results['uniform_central_scasim'][0])\n",
        "\n",
        "      ez_reader_mse_dur_all_folds.extend(reader_results['ez_reader_mse_dur'][0])\n",
        "      ez_reader_mse_land_pos_all_folds.extend(reader_results['ez_reader_mse_land_pos'][0])\n",
        "      ez_reader_scasim_all_folds.extend(reader_results['ez_reader_scasim'][0])\n",
        "      ez_reader_central_scasim_all_folds.extend(reader_results['ez_reader_central_scasim'][0])\n",
        "\n",
        "      fold_index += 1\n",
        "\n",
        "# Calculate overall statistics\n",
        "def calculate_mean_and_se(values):\n",
        "    mean_val = np.mean(values)\n",
        "    se_val = np.std(values) / np.sqrt(len(values))\n",
        "    return mean_val, se_val\n",
        "\n",
        "mean_nll, se_nll = calculate_mean_and_se(test_ll_all_folds)\n",
        "mean_mse_dur, se_mse_dur = calculate_mean_and_se(test_mse_dur_all_folds)\n",
        "mean_mse_land_pos, se_mse_land_pos = calculate_mean_and_se(test_mse_land_pos_all_folds)\n",
        "mean_scasim, se_scasim = calculate_mean_and_se(scasim_dnn_all_folds)\n",
        "mean_central_scasim, se_central_scasim = calculate_mean_and_se(central_scasim_dnn_all_folds)\n",
        "mean_scasim_human, se_scasim_human = calculate_mean_and_se(scasim_human_all_folds)\n",
        "mean_central_scasim_human, se_central_scasim_human = calculate_mean_and_se(central_scasim_human_all_folds)\n",
        "\n",
        "mean_nll_uniform, se_nll_uniform = calculate_mean_and_se(uniform_ll_all_folds)\n",
        "mean_mse_dur_uniform, se_mse_dur_uniform = calculate_mean_and_se(uniform_mse_dur_all_folds)\n",
        "mean_mse_land_pos_uniform, se_mse_land_pos_uniform = calculate_mean_and_se(uniform_mse_land_pos_all_folds)\n",
        "mean_scasim_uniform, se_scasim_uniform = calculate_mean_and_se(uniform_scasim_all_folds)\n",
        "mean_central_scasim_uniform, se_central_scasim_uniform = calculate_mean_and_se(uniform_central_scasim_all_folds)\n",
        "\n",
        "mean_nll_ez_reader, se_nll_ez_reader = calculate_mean_and_se(ez_reader_mse_dur_all_folds)\n",
        "mean_mse_dur_ez_reader, se_mse_dur_ez_reader = calculate_mean_and_se(ez_reader_mse_dur_all_folds)\n",
        "mean_mse_land_pos_ez_reader, se_mse_land_pos_ez_reader = calculate_mean_and_se(ez_reader_mse_land_pos_all_folds)\n",
        "mean_scasim_ez_reader, se_scasim_ez_reader = calculate_mean_and_se(ez_reader_scasim_all_folds)\n",
        "mean_central_scasim_ez_reader, se_central_scasim_ez_reader = calculate_mean_and_se(ez_reader_central_scasim_all_folds)\n",
        "\n",
        "\n",
        "print(\"Overall Mean NLL:\", mean_nll)\n",
        "print(\"Overall Standard error NLL:\", se_nll)\n",
        "\n",
        "print(\"Overall Mean MSE dur:\", mean_mse_dur)\n",
        "print(\"Overall Standard error MSE dur:\", se_mse_dur)\n",
        "\n",
        "print(\"Overall Mean MSE landing pos:\", mean_mse_land_pos)\n",
        "print(\"Overall Standard error MSE landing pos:\", se_mse_land_pos)\n",
        "\n",
        "print(\"Overall Mean scasim:\", mean_scasim)\n",
        "print(\"Overall Standard error scasim:\", se_scasim)\n",
        "\n",
        "print(\"Overall Mean Central scasim:\", mean_central_scasim)\n",
        "print(\"Overall Standard error Central scasim:\", se_central_scasim)\n",
        "\n",
        "print(\"Human Mean scasim:\", mean_scasim_human)\n",
        "print(\"Human Standard error scasim:\", se_scasim_human)\n",
        "\n",
        "print(\"Human Mean central scasim:\", mean_central_scasim_human)\n",
        "print(\"Human Standard error central scasim:\", se_central_scasim_human)\n",
        "\n",
        "\n",
        "print(\"Overall Mean NLL Uniform:\", mean_nll_uniform)\n",
        "print(\"Overall Standard error NLL:\", se_nll_uniform)\n",
        "\n",
        "print(\"Overall Mean MSE dur Uniform:\", mean_mse_dur_uniform)\n",
        "print(\"Overall Standard error MSE dur Uniform:\", se_mse_dur_uniform)\n",
        "\n",
        "print(\"Overall Mean MSE landing pos Uniform:\", mean_mse_land_pos_uniform)\n",
        "print(\"Overall Standard error MSE landing pos:\", se_mse_land_pos_uniform)\n",
        "\n",
        "print(\"Overall Mean scasim Uniform:\", mean_scasim_uniform)\n",
        "print(\"Overall Standard error scasim:\", se_scasim_uniform)\n",
        "\n",
        "print(\"Overall Mean Central scasim Uniform:\", mean_central_scasim_uniform)\n",
        "print(\"Overall Standard error Central scasim:\", se_central_scasim_uniform)\n",
        "\n",
        "\n",
        "print(\"Overall Mean MSE dur E-Z Reader:\", mean_mse_dur_ez_reader)\n",
        "print(\"Overall Standard error MSE dur E-Z Reader:\", se_mse_dur_ez_reader)\n",
        "\n",
        "print(\"Overall Mean MSE landing pos E-Z Reader:\", mean_mse_land_pos_ez_reader)\n",
        "print(\"Overall Standard error MSE landing pos:\", se_mse_land_pos_ez_reader)\n",
        "\n",
        "print(\"Overall Mean scasim E-Z Reader:\", mean_scasim_ez_reader)\n",
        "print(\"Overall Standard error scasim:\", se_scasim_ez_reader)\n",
        "\n",
        "print(\"Overall Mean Central scasim E-Z Reader:\", mean_central_scasim_ez_reader)\n",
        "print(\"Overall Standard error Central scasim:\", se_central_scasim_ez_reader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqOvapgPO6qj",
        "outputId": "f2cece72-edc5-4628-9b8b-8916dd4416ba"
      },
      "id": "LqOvapgPO6qj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Mean NLL: -2.2320598291221567\n",
            "Overall Standard error NLL: 0.0057360386230212255\n",
            "Overall Mean MSE dur: 0.2334607392691187\n",
            "Overall Standard error MSE dur: 0.05873493065957505\n",
            "Overall Mean MSE landing pos: 0.03510107358227018\n",
            "Overall Standard error MSE landing pos: 0.001998176880134585\n",
            "Overall Mean scasim: 2631.2392362411083\n",
            "Overall Standard error scasim: 24.338579533477546\n",
            "Overall Mean Central scasim: 1869.731374017222\n",
            "Overall Standard error Central scasim: 20.209177486746935\n",
            "Human Mean scasim: 3074.6010857356796\n",
            "Human Standard error scasim: 27.129219140903757\n",
            "Human Mean central scasim: 1961.1666042680645\n",
            "Human Standard error central scasim: 19.73956215720687\n",
            "Overall Mean NLL Uniform: -5.4918532371521\n",
            "Overall Standard error NLL: 0.0\n",
            "Overall Mean MSE dur Uniform: 4.658361274458495\n",
            "Overall Standard error MSE dur Uniform: 0.12895413332779163\n",
            "Overall Mean MSE landing pos Uniform: 2.2525895910498215\n",
            "Overall Standard error MSE landing pos: 0.01686352599298797\n",
            "Overall Mean scasim Uniform: 4880.554855529002\n",
            "Overall Standard error scasim: 43.781397045930795\n",
            "Overall Mean Central scasim Uniform: 4094.8600912448405\n",
            "Overall Standard error Central scasim: 44.952157311535046\n",
            "Overall Mean MSE dur E-Z Reader: 9.526822275218112\n",
            "Overall Standard error MSE dur E-Z Reader: 0.13029694749431323\n",
            "Overall Mean MSE landing pos E-Z Reader: 2.415685949913759\n",
            "Overall Standard error MSE landing pos: 0.016380240835858217\n",
            "Overall Mean scasim E-Z Reader: 2937.926618415762\n",
            "Overall Standard error scasim: 21.276539811778562\n",
            "Overall Mean Central scasim E-Z Reader: 1599.3552472858867\n",
            "Overall Standard error Central scasim: 8.63065196881935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "fold_index = 0\n",
        "for i in range(5):\n",
        "  with open(f'drive/MyDrive/results/celer/New_Reader/res_CELER_subject_eyettention_local_g_Fold{fold_index}.pickle', 'rb') as handle:\n",
        "      print(fold_index)\n",
        "      fold_results = pickle.load(handle)\n",
        "\n",
        "      # NLL\n",
        "      test_ll = fold_results['test_ll'][0]\n",
        "\n",
        "  #    with open(f'drive/MyDrive/results/celer/New_Sentence/res_CELER_original_eyettention_fold{fold_index}.pickle', 'rb') as original:\n",
        "   #     original_results = pickle.load(original)\n",
        "   #     original_ll = original_results['test_ll'][0]\n",
        "    #    t_statistic, p_value = stats.ttest_ind(test_ll, original_ll)\n",
        "        # Interpretation based on p-value\n",
        "  #      if p_value < 0.05:\n",
        "   #       print(\"Reject null hypothesis: Statistically significant difference in NLL scores between Eyettention 2.0 and original Eyettention scanpaths.\")\n",
        "    #    else:\n",
        "     #     print(\"Fail to reject null hypothesis: No statistically significant difference found between Eyettention 2.0 and original Eyettention NLL scores.\")\n",
        "\n",
        "      uniform_nll = fold_results['uniform_nll'][0]\n",
        "\n",
        "      t_statistic, p_value = stats.ttest_ind(test_ll, uniform_nll)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in NLL scores between predicted and uniformly generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between the predicted and uniform NLL scores.\")\n",
        "\n",
        "      # Scasim\n",
        "      scasim_dnn = fold_results['scasim_dnn'][0]\n",
        "      scasim_human = fold_results['scasim_human'][0]\n",
        "      ez_reader_scasim = fold_results['ez_reader_scasim'][0]\n",
        "      uniform_scasim = fold_results['uniform_scasim'][0]\n",
        "\n",
        "      t_statistic, p_value = stats.ttest_ind(scasim_dnn, ez_reader_scasim)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and E-Z Reader generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and E-Z Reader generated Scasim scores.\")\n",
        "      t_statistic, p_value = stats.ttest_ind(scasim_dnn, uniform_scasim)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the uniform generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and uniform Scasim scores.\")\n",
        "\n",
        "      t_statistic, p_value = stats.ttest_ind(scasim_dnn, scasim_human)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the human scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and human Scasim scores.\")\n",
        "\n",
        "      # Central Scasim\n",
        "      central_scasim_dnn = fold_results['central_scasim_dnn'][0]\n",
        "      central_scasim_human = fold_results['central_scasim_human'][0]\n",
        "      ez_reader_central_scasim = fold_results['ez_reader_central_scasim'][0]\n",
        "      uniform_central_scasim = fold_results['uniform_central_scasim'][0]\n",
        "\n",
        "      t_statistic, p_value = stats.ttest_ind(central_scasim_dnn, ez_reader_central_scasim)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and E-Z Reader generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and E-Z Reader Central Scasim scores.\")\n",
        "      t_statistic, p_value = stats.ttest_ind(central_scasim_dnn, uniform_central_scasim)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the uniform generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and uniform Central Scasim scores.\")\n",
        "\n",
        "      t_statistic, p_value = stats.ttest_ind(central_scasim_dnn, central_scasim_human)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the human scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and human Central Scasim scores.\")\n",
        "\n",
        "      # MSE durations\n",
        "      test_mse_dur = fold_results['test_mse_dur'][0]\n",
        "      ez_reader_mse_dur = fold_results['ez_reader_mse_dur'][0]\n",
        "      uniform_mse_dur = fold_results['uniform_mse_dur'][0]\n",
        "\n",
        "      t_statistic, p_value = stats.ttest_ind(test_mse_dur, ez_reader_mse_dur)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and E-Z Reader generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and E-Z Reader MSE scores for durations.\")\n",
        "      t_statistic, p_value = stats.ttest_ind(test_mse_dur, uniform_mse_dur)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and the uniform generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and uniform MSE scores for durations.\")\n",
        "\n",
        "      # MSE landing pos\n",
        "      test_mse_land_pos = fold_results['test_mse_land_pos'][0]\n",
        "      ez_reader_mse_land_pos = fold_results['ez_reader_mse_land_pos'][0]\n",
        "      uniform_mse_land_pos = fold_results['uniform_mse_land_pos'][0]\n",
        "\n",
        "      t_statistic, p_value = stats.ttest_ind(test_mse_land_pos, ez_reader_mse_land_pos)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and E-Z Reader generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and E-Z Reader MSE scores for landing pos.\")\n",
        "      t_statistic, p_value = stats.ttest_ind(test_mse_land_pos, uniform_mse_land_pos)\n",
        "      # Interpretation based on p-value\n",
        "      if p_value < 0.05:\n",
        "        print(\"Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and the uniform generated scanpaths.\")\n",
        "      else:\n",
        "        print(\"Fail to reject null hypothesis: No statistically significant difference between predicted and uniform MSE scores for landing pos.\")\n",
        "\n",
        "      fold_index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3Ocu-P6PvX5",
        "outputId": "2f410961-7638-412e-eca9-c205977cc178"
      },
      "id": "k3Ocu-P6PvX5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Reject null hypothesis: Statistically significant difference in NLL scores between predicted and uniformly generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the human scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Fail to reject null hypothesis: No statistically significant difference between predicted and human Central Scasim scores.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and the uniform generated scanpaths.\n",
            "1\n",
            "Reject null hypothesis: Statistically significant difference in NLL scores between predicted and uniformly generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the human scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Fail to reject null hypothesis: No statistically significant difference between predicted and human Central Scasim scores.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and the uniform generated scanpaths.\n",
            "2\n",
            "Reject null hypothesis: Statistically significant difference in NLL scores between predicted and uniformly generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the human scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the human scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and the uniform generated scanpaths.\n",
            "3\n",
            "Reject null hypothesis: Statistically significant difference in NLL scores between predicted and uniformly generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the human scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Fail to reject null hypothesis: No statistically significant difference between predicted and human Central Scasim scores.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and the uniform generated scanpaths.\n",
            "4\n",
            "Reject null hypothesis: Statistically significant difference in NLL scores between predicted and uniformly generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Scasim scores between predicted and the human scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in Central Scasim scores between predicted and the human scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for durations between predicted and the uniform generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and E-Z Reader generated scanpaths.\n",
            "Reject null hypothesis: Statistically significant difference in MSE scores for landing pos between predicted and the uniform generated scanpaths.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed779e65e0244b2c804670d80fd43941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c850219e15b74090a2c7a5b09169b263",
              "IPY_MODEL_26a35d039347436b87a63fbd884cad98",
              "IPY_MODEL_b02c0a217c4140e296e54c9e87530c02"
            ],
            "layout": "IPY_MODEL_936becaad1e4421d9d35524ccbd33af0"
          }
        },
        "c850219e15b74090a2c7a5b09169b263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f99f01470094e4db369df53b964b64d",
            "placeholder": "​",
            "style": "IPY_MODEL_0a2a5267af984eadb209020a6d65054d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "26a35d039347436b87a63fbd884cad98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70603e4b6f64488d8a9542bef926bbeb",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_948b18569e7d4f53be9f0b290f798d2c",
            "value": 49
          }
        },
        "b02c0a217c4140e296e54c9e87530c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c531120925d428b82e123d9a3889e2a",
            "placeholder": "​",
            "style": "IPY_MODEL_178ebf8ce8a040b48f87cfd7e3aa6d42",
            "value": " 49.0/49.0 [00:00&lt;00:00, 2.57kB/s]"
          }
        },
        "936becaad1e4421d9d35524ccbd33af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f99f01470094e4db369df53b964b64d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2a5267af984eadb209020a6d65054d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70603e4b6f64488d8a9542bef926bbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948b18569e7d4f53be9f0b290f798d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c531120925d428b82e123d9a3889e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "178ebf8ce8a040b48f87cfd7e3aa6d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1034d5c1f16d432686a1584c04774796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04941b5000214b5bb7d3b649c35b32f4",
              "IPY_MODEL_a9f9299003114b0db7f551d3c2849d93",
              "IPY_MODEL_75ede2edfec14179af72a6ef8b23971c"
            ],
            "layout": "IPY_MODEL_2e29123734714afbba6465f1331b2b11"
          }
        },
        "04941b5000214b5bb7d3b649c35b32f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0fcbd640524a31b468a3f941b9a11b",
            "placeholder": "​",
            "style": "IPY_MODEL_d44e32edab314dc3a0b4a4491d8627d0",
            "value": "vocab.txt: 100%"
          }
        },
        "a9f9299003114b0db7f551d3c2849d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5fe405759c44a30a4d361017700fd8b",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43ffdd89658b4fe78487013558d8ba89",
            "value": 213450
          }
        },
        "75ede2edfec14179af72a6ef8b23971c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0ef8c79a23429f98dd875cd8955348",
            "placeholder": "​",
            "style": "IPY_MODEL_6c3d7d1f34894ebab94d94dc56720a62",
            "value": " 213k/213k [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "2e29123734714afbba6465f1331b2b11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a0fcbd640524a31b468a3f941b9a11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44e32edab314dc3a0b4a4491d8627d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5fe405759c44a30a4d361017700fd8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ffdd89658b4fe78487013558d8ba89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d0ef8c79a23429f98dd875cd8955348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c3d7d1f34894ebab94d94dc56720a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "520ec5afdb3d4d41981197585e2c4557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca0369599e8b44baa9acc3878b1214f7",
              "IPY_MODEL_089f664d5bb44d0589a233e2fc61f6e6",
              "IPY_MODEL_3caf567beddf4a528b28d0e549e3bcda"
            ],
            "layout": "IPY_MODEL_9d322dfd054d43f2828b7dc9fa088e61"
          }
        },
        "ca0369599e8b44baa9acc3878b1214f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea53ac6939e344719214a466fc109237",
            "placeholder": "​",
            "style": "IPY_MODEL_60b6d79ea74649de81c3ab4496889c06",
            "value": "tokenizer.json: 100%"
          }
        },
        "089f664d5bb44d0589a233e2fc61f6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca482e85ad704a76b0b4241e57a0a2c3",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a510322d6504fb28832aeb7ea0eeffc",
            "value": 435797
          }
        },
        "3caf567beddf4a528b28d0e549e3bcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af80c298cce64c578fe8facbbf55e54b",
            "placeholder": "​",
            "style": "IPY_MODEL_e1fd2e9e2c7e4f5688082395f6f1289f",
            "value": " 436k/436k [00:00&lt;00:00, 3.24MB/s]"
          }
        },
        "9d322dfd054d43f2828b7dc9fa088e61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea53ac6939e344719214a466fc109237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b6d79ea74649de81c3ab4496889c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca482e85ad704a76b0b4241e57a0a2c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a510322d6504fb28832aeb7ea0eeffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af80c298cce64c578fe8facbbf55e54b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1fd2e9e2c7e4f5688082395f6f1289f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77f95906afd743f283004fe7a63fc740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65f9af198f3b423f9cfbd1114a06e5a9",
              "IPY_MODEL_dec3e1f095cb454ba3f4d6bc4eda4e1f",
              "IPY_MODEL_3abb9356d90a4d13867fdb24bbafb9c9"
            ],
            "layout": "IPY_MODEL_a8153ee371c045febf3771f3696c24fa"
          }
        },
        "65f9af198f3b423f9cfbd1114a06e5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af16bde493af4b28b129b6be884a2489",
            "placeholder": "​",
            "style": "IPY_MODEL_48b927397c2b443ca9c9934d7987d649",
            "value": "config.json: 100%"
          }
        },
        "dec3e1f095cb454ba3f4d6bc4eda4e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cebe26b277f04bf1bd084f30734b5c41",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f37ca9aaf4524b6997146b187a270a4e",
            "value": 570
          }
        },
        "3abb9356d90a4d13867fdb24bbafb9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7027c79882b4320a23fd0376f98812e",
            "placeholder": "​",
            "style": "IPY_MODEL_8cbadab4b26f4a9098e21ffeb38aad0d",
            "value": " 570/570 [00:00&lt;00:00, 27.4kB/s]"
          }
        },
        "a8153ee371c045febf3771f3696c24fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af16bde493af4b28b129b6be884a2489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48b927397c2b443ca9c9934d7987d649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cebe26b277f04bf1bd084f30734b5c41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37ca9aaf4524b6997146b187a270a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7027c79882b4320a23fd0376f98812e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cbadab4b26f4a9098e21ffeb38aad0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf699a56c6eb468d87db86ded607dfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c138ce3ac2c468599e9014c05843e65",
              "IPY_MODEL_7d48e5c6540243d887bbc03c88ffb16b",
              "IPY_MODEL_531ece5c80dd46fea721265223c3d2c0"
            ],
            "layout": "IPY_MODEL_f18fb33cfba04655befa99ac7624a087"
          }
        },
        "5c138ce3ac2c468599e9014c05843e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17ba8d7aaa6545a3af29a00d666e5890",
            "placeholder": "​",
            "style": "IPY_MODEL_f3b0d75866724b01978763396123b2d4",
            "value": "model.safetensors: 100%"
          }
        },
        "7d48e5c6540243d887bbc03c88ffb16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_404b9a055c7d410da0d7e90f6990565f",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c7f975e248749cda8039b83b4619e67",
            "value": 435755784
          }
        },
        "531ece5c80dd46fea721265223c3d2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88a0cf764880430b950da216ea29a47a",
            "placeholder": "​",
            "style": "IPY_MODEL_4578a38620e9457385642e1950208ec3",
            "value": " 436M/436M [00:07&lt;00:00, 19.3MB/s]"
          }
        },
        "f18fb33cfba04655befa99ac7624a087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ba8d7aaa6545a3af29a00d666e5890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b0d75866724b01978763396123b2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "404b9a055c7d410da0d7e90f6990565f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7f975e248749cda8039b83b4619e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88a0cf764880430b950da216ea29a47a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4578a38620e9457385642e1950208ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}