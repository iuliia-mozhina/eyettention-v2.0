{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "nuclear-dream",
      "metadata": {
        "id": "nuclear-dream"
      },
      "source": [
        "# Eyettention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0978c758-ea14-4df4-97d0-6e0c1ed18428",
      "metadata": {
        "id": "0978c758-ea14-4df4-97d0-6e0c1ed18428"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import model\n",
        "import torch\n",
        "from torch.utils import model_zoo\n",
        "import pandas as pd\n",
        "from utils import *\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam, RMSprop\n",
        "from transformers import BertTokenizerFast\n",
        "from model import Eyettention_readerID\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from torch.nn.functional import cross_entropy, softmax\n",
        "from collections import deque\n",
        "import pickle\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import random\n",
        "from scasim import *\n",
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8dfb0f8-8775-4609-b75c-6052916ca9c0",
      "metadata": {
        "id": "c8dfb0f8-8775-4609-b75c-6052916ca9c0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "#DEVICE = 'cuda'\n",
        "DEVICE = 'cpu'\n",
        "scanpath_gen_flag = True\n",
        "atten_type = \"local_g\"\n",
        "save_data_folder = \"./drive/MyDrive/results/BSC/Eyettention_Reader/emb_size_64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4l7DoNdYwUn9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l7DoNdYwUn9",
        "outputId": "0cf42f99-8a64-4f16-8c3a-591289f6eb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e085041-7c16-44b4-9129-bf667f64c552",
      "metadata": {
        "id": "6e085041-7c16-44b4-9129-bf667f64c552"
      },
      "source": [
        "**Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28WYhnrePEZj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28WYhnrePEZj",
        "outputId": "12eab06c-680d-48ec-b89c-23434f250502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start evaluating on new sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Evaluating for fold 0\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.020104618552977627\n",
            "MSE for landing positions 0.014165729791784543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1345.546875\n",
            "Mean scasim human 1958.22265625\n",
            "Mean central scasim dnn 985.35546875\n",
            "Mean central scasim human 1232.12109375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.022530937165811338\n",
            "MSE for landing positions 0.014331071230344605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1278.9921875\n",
            "Mean scasim human 1601.046875\n",
            "Mean central scasim dnn 958.51953125\n",
            "Mean central scasim human 1223.3046875\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02343079150136873\n",
            "MSE for landing positions 0.015731161121038895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1590.37109375\n",
            "Mean scasim human 1849.6796875\n",
            "Mean central scasim dnn 1328.69140625\n",
            "Mean central scasim human 1529.265625\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.027691648410836933\n",
            "MSE for landing positions 0.016114772654646004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1496.53125\n",
            "Mean scasim human 1804.27734375\n",
            "Mean central scasim dnn 1109.80859375\n",
            "Mean central scasim human 1427.4375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.03810682073253702\n",
            "MSE for landing positions 0.017794159804452647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1651.84375\n",
            "Mean scasim human 2024.109375\n",
            "Mean central scasim dnn 1244.7109375\n",
            "Mean central scasim human 1555.453125\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.028498677995230537\n",
            "MSE for landing positions 0.017725731196151173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1587.30078125\n",
            "Mean scasim human 2330.9921875\n",
            "Mean central scasim dnn 1148.3203125\n",
            "Mean central scasim human 1515.46875\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02699753182016082\n",
            "MSE for landing positions 0.015924101622320365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1571.1317829457364\n",
            "Mean scasim human 2106.9922480620153\n",
            "Mean central scasim dnn 998.5891472868217\n",
            "Mean central scasim human 1486.9767441860465\n",
            "Test likelihood is -1.7063532229504164\n",
            "Standard error for NLL 0.01668078753773475\n",
            "Test MSE for durations is 0.026748189886272592\n",
            "Standard error for MSE dur 0.0016587339361378115\n",
            "Test MSE for landing positions is 0.01597299778599057\n",
            "Standard error for MSE land pos 0.00031287554719322194\n",
            "Central Scasim dnn 1119.1123123123123\n",
            "Standard error for Central scasim DNN 11.15437896429574\n",
            "Central Scasim human 1419.5081081081082\n",
            "Standard error for Central scasim human 15.870360984482755\n",
            "Scasim dnn 1497.9135135135134\n",
            "Standard error for scasim dnn 16.59213294453015\n",
            "Scasim human 1941.9183183183184\n",
            "Standard error for scasim human 18.59812566758492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Evaluating for fold 1\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02403234313271696\n",
            "MSE for landing positions 0.01497217992550759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1333.11328125\n",
            "Mean scasim human 2131.95703125\n",
            "Mean central scasim dnn 1019.87890625\n",
            "Mean central scasim human 1258.2109375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.029464269882737426\n",
            "MSE for landing positions 0.017094335168167163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1572.78515625\n",
            "Mean scasim human 1881.42578125\n",
            "Mean central scasim dnn 1213.7578125\n",
            "Mean central scasim human 1504.40234375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02928394004902657\n",
            "MSE for landing positions 0.018433299781463575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1748.421875\n",
            "Mean scasim human 2171.96875\n",
            "Mean central scasim dnn 1234.58984375\n",
            "Mean central scasim human 1668.89453125\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.023247076700954494\n",
            "MSE for landing positions 0.016586749208272522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1481.73046875\n",
            "Mean scasim human 1984.28515625\n",
            "Mean central scasim dnn 1149.61328125\n",
            "Mean central scasim human 1400.32421875\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.025800976158734557\n",
            "MSE for landing positions 0.0169989614860242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1646.82421875\n",
            "Mean scasim human 2034.140625\n",
            "Mean central scasim dnn 1258.77734375\n",
            "Mean central scasim human 1573.20703125\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.03426080622853078\n",
            "MSE for landing positions 0.019135805991709276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1826.82421875\n",
            "Mean scasim human 2348.76953125\n",
            "Mean central scasim dnn 1301.01171875\n",
            "Mean central scasim human 1710.8203125\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02511788024321983\n",
            "MSE for landing positions 0.017311580996274164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1618.9052631578948\n",
            "Mean scasim human 2076.684210526316\n",
            "Mean central scasim dnn 1125.9789473684211\n",
            "Mean central scasim human 1601.6105263157895\n",
            "Test likelihood is -1.6739646501951082\n",
            "Standard error for NLL 0.01540914844591275\n",
            "Test MSE for durations is 0.027532242878109923\n",
            "Standard error for MSE dur 0.0009107881491094707\n",
            "Test MSE for landing positions is 0.017209847378478842\n",
            "Standard error for MSE land pos 0.00030188373714650293\n",
            "Central Scasim dnn 1192.1771919068055\n",
            "Standard error for Central scasim DNN 10.65965850346854\n",
            "Central Scasim human 1524.1036174126302\n",
            "Standard error for Central scasim human 17.039440717856284\n",
            "Scasim dnn 1602.6235438381361\n",
            "Standard error for scasim dnn 17.444006162214325\n",
            "Scasim human 2091.193746167995\n",
            "Standard error for scasim human 20.104282372591037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Evaluating for fold 2\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.025730273594263053\n",
            "MSE for landing positions 0.016699319310646388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1524.95703125\n",
            "Mean scasim human 2119.8046875\n",
            "Mean central scasim dnn 1133.19140625\n",
            "Mean central scasim human 1419.109375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.03544972696499826\n",
            "MSE for landing positions 0.017912964245397234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1533.65234375\n",
            "Mean scasim human 2118.5546875\n",
            "Mean central scasim dnn 1104.0703125\n",
            "Mean central scasim human 1503.671875\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.025673802474557306\n",
            "MSE for landing positions 0.01679855188467627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1613.53125\n",
            "Mean scasim human 2262.96484375\n",
            "Mean central scasim dnn 1121.18359375\n",
            "Mean central scasim human 1532.1640625\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.027251346106822893\n",
            "MSE for landing positions 0.017354263374727452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1589.25390625\n",
            "Mean scasim human 1938.1171875\n",
            "Mean central scasim dnn 1234.8203125\n",
            "Mean central scasim human 1504.34765625\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02797846850626229\n",
            "MSE for landing positions 0.01752608042488646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1607.94140625\n",
            "Mean scasim human 2551.515625\n",
            "Mean central scasim dnn 1186.0\n",
            "Mean central scasim human 1531.99609375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02959459999419778\n",
            "MSE for landing positions 0.019071004137458658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1749.19921875\n",
            "Mean scasim human 2405.03515625\n",
            "Mean central scasim dnn 1224.5703125\n",
            "Mean central scasim human 1680.015625\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.024696816482160867\n",
            "MSE for landing positions 0.016107698045341314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1637.2477876106195\n",
            "Mean scasim human 1908.070796460177\n",
            "Mean central scasim dnn 1261.6194690265486\n",
            "Mean central scasim human 1486.6017699115043\n",
            "Test likelihood is -1.6659939160000978\n",
            "Standard error for NLL 0.0146455686428165\n",
            "Test MSE for durations is 0.028344671909403384\n",
            "Standard error for MSE dur 0.001414337033659194\n",
            "Test MSE for landing positions is 0.017460817964729192\n",
            "Standard error for MSE land pos 0.0003895428018365338\n",
            "Central Scasim dnn 1173.7689508793208\n",
            "Standard error for Central scasim DNN 11.024375247623341\n",
            "Central Scasim human 1525.6761673741662\n",
            "Standard error for Central scasim human 16.59091610743915\n",
            "Scasim dnn 1605.4299575500304\n",
            "Standard error for scasim dnn 17.91386745705258\n",
            "Scasim human 2210.422073984233\n",
            "Standard error for scasim human 20.60278866120845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Evaluating for fold 3\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.025644212037150282\n",
            "MSE for landing positions 0.015716443847168193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1466.37109375\n",
            "Mean scasim human 1920.0078125\n",
            "Mean central scasim dnn 1084.0703125\n",
            "Mean central scasim human 1385.4296875\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.025572775271939463\n",
            "MSE for landing positions 0.020074330001989438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1556.17578125\n",
            "Mean scasim human 2150.453125\n",
            "Mean central scasim dnn 1153.57421875\n",
            "Mean central scasim human 1447.48828125\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.01879255891753928\n",
            "MSE for landing positions 0.013868569046735502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1282.8125\n",
            "Mean scasim human 1605.2265625\n",
            "Mean central scasim dnn 944.5546875\n",
            "Mean central scasim human 1212.3046875\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.03188676596801088\n",
            "MSE for landing positions 0.019465651340397017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1809.234375\n",
            "Mean scasim human 2252.3671875\n",
            "Mean central scasim dnn 1423.390625\n",
            "Mean central scasim human 1737.0859375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.025853953962723608\n",
            "MSE for landing positions 0.01773369721013296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1683.59765625\n",
            "Mean scasim human 1987.1171875\n",
            "Mean central scasim dnn 1300.44921875\n",
            "Mean central scasim human 1509.62109375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.027906900439802484\n",
            "MSE for landing positions 0.01637170264575616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1642.37109375\n",
            "Mean scasim human 1843.7734375\n",
            "Mean central scasim dnn 1275.25\n",
            "Mean central scasim human 1541.3671875\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02278064302173538\n",
            "MSE for landing positions 0.016996121102925008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1384.6734693877552\n",
            "Mean scasim human 1700.591836734694\n",
            "Mean central scasim dnn 1016.1428571428571\n",
            "Mean central scasim human 1333.0\n",
            "Test likelihood is -1.5992242306377342\n",
            "Standard error for NLL 0.014576616192985467\n",
            "Test MSE for durations is 0.02575320542533939\n",
            "Standard error for MSE dur 0.000890126171575056\n",
            "Test MSE for landing positions is 0.017192534122205963\n",
            "Standard error for MSE land pos 0.00033525583182291417\n",
            "Central Scasim dnn 1186.0416156670747\n",
            "Standard error for Central scasim DNN 12.283164260057383\n",
            "Central Scasim human 1463.8665850673194\n",
            "Standard error for Central scasim human 16.186334167544775\n",
            "Scasim dnn 1562.1064871481028\n",
            "Standard error for scasim dnn 17.879959152947563\n",
            "Scasim human 1944.2766217870258\n",
            "Standard error for scasim human 19.14795062721589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keeping Bert with pre-trained weights\n",
            "Evaluating for fold 4\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.021821808593585956\n",
            "MSE for landing positions 0.01480568557440165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1419.80078125\n",
            "Mean scasim human 1942.66015625\n",
            "Mean central scasim dnn 1081.12890625\n",
            "Mean central scasim human 1402.1328125\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.024219427459684084\n",
            "MSE for landing positions 0.014660380513305427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1434.15234375\n",
            "Mean scasim human 1664.2109375\n",
            "Mean central scasim dnn 1053.109375\n",
            "Mean central scasim human 1324.73828125\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02776871210517129\n",
            "MSE for landing positions 0.016509522770320473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1543.578125\n",
            "Mean scasim human 1957.50390625\n",
            "Mean central scasim dnn 1200.55078125\n",
            "Mean central scasim human 1507.52734375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.02514451653087235\n",
            "MSE for landing positions 0.016753797471665166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1647.625\n",
            "Mean scasim human 2263.51953125\n",
            "Mean central scasim dnn 1283.92578125\n",
            "Mean central scasim human 1566.34765625\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.026133705197480595\n",
            "MSE for landing positions 0.017363432191359607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1583.36328125\n",
            "Mean scasim human 2043.3125\n",
            "Mean central scasim dnn 1099.59765625\n",
            "Mean central scasim human 1513.3515625\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.029502922757501437\n",
            "MSE for landing positions 0.017443085308968875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1599.95703125\n",
            "Mean scasim human 2396.36328125\n",
            "Mean central scasim dnn 1280.4609375\n",
            "Mean central scasim human 1544.7734375\n",
            "######### Eyettention Reader 2.0 model evaluation ##########\n",
            "MSE for durations 0.025914144987077677\n",
            "MSE for landing positions 0.01729224621006333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:303: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = torch.tensor(item)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean scasim dnn 1593.8155339805826\n",
            "Mean scasim human 1822.2815533980583\n",
            "Mean central scasim dnn 1223.2621359223301\n",
            "Mean central scasim human 1584.2621359223301\n",
            "Test likelihood is -1.663116664937798\n",
            "Standard error for NLL 0.014766350952615736\n",
            "Test MSE for durations is 0.025774543410987616\n",
            "Standard error for MSE dur 0.0007489008936140284\n",
            "Test MSE for landing positions is 0.016321106003735174\n",
            "Standard error for MSE land pos 0.0002996371923271074\n",
            "Central Scasim dnn 1170.031726662599\n",
            "Standard error for Central scasim DNN 10.564486795784891\n",
            "Central Scasim human 1483.2519829164125\n",
            "Standard error for Central scasim human 15.589180798345229\n",
            "Scasim dnn 1541.5820622330689\n",
            "Standard error for scasim dnn 16.64419453118263\n",
            "Scasim human 2030.6241610738255\n",
            "Standard error for scasim human 19.491783643051676\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\tgpu = 0\n",
        "\n",
        "\ttorch.set_default_tensor_type('torch.FloatTensor')\n",
        "\tavailbl = torch.cuda.is_available()\n",
        "\tif availbl:\n",
        "\t\tdevice = f'cuda:{gpu}'\n",
        "\telse:\n",
        "\t\tdevice = 'cpu'\n",
        "\t#torch.cuda.set_device(gpu)\n",
        "\n",
        "\tcf = {\"model_pretrained\": \"bert-base-chinese\",\n",
        "\t\t\t\"lr\": 1e-3,\n",
        "\t\t\t\"max_grad_norm\": 10,\n",
        "\t\t\t\"n_epochs\": 150,  # 1000\n",
        "\t\t\t\"n_folds\": 5,\n",
        "\t\t\t\"dataset\": 'BSC',\n",
        "\t\t\t\"atten_type\": 'local-g',\n",
        "\t\t\t\"subid_emb_size\": 64, # 32, 64\n",
        "\t\t\t\"batch_size\": 256,\n",
        "\t\t\t\"max_sn_len\": 27, #include start token and end token\n",
        "\t\t\t\"max_sp_len\": 40, #include start token and end token\n",
        "\t\t\t\"norm_type\": \"z-score\",\n",
        "\t\t\t\"earlystop_patience\": 20,\n",
        "\t\t\t\"max_pred_len\": 60\n",
        "\t\t\t}\n",
        "\n",
        "\t#Encode the label into interger categories, setting the exclusive category 'cf[\"max_sn_len\"]-1' as the end sign\n",
        "\tle = LabelEncoder()\n",
        "\tle.fit(np.append(np.arange(-cf[\"max_sn_len\"]+3, cf[\"max_sn_len\"]-1), cf[\"max_sn_len\"]-1))\n",
        "\t#le.classes_\n",
        "\n",
        "\t#load corpus\n",
        "\tword_info_df, pos_info_df, eyemovement_df = load_corpus(cf[\"dataset\"])\n",
        "\t#Make list with sentence index\n",
        "\tsn_list = np.unique(eyemovement_df.sn.values).tolist()\n",
        "\t#Make list with reader index\n",
        "\treader_list = np.unique(eyemovement_df.id.values).tolist()\n",
        "\n",
        "\tprint('Start evaluating on new sentences.')\n",
        "\tsplit_list = sn_list\n",
        "\n",
        "\tn_folds = cf[\"n_folds\"]\n",
        "\tkf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
        "\tfold_indx = 0\n",
        "\t#for scanpath generation\n",
        "\tsp_dnn_list = []\n",
        "\tsp_human_list = []\n",
        "\tfor train_idx, test_idx in kf.split(split_list):\n",
        "\t\tloss_dict = {'val_loss':[], 'train_loss':[], 'test_ll':[], 'test_ll_SE':[], 'test_mse_dur':[], 'test_mse_dur_SE':[], 'test_mse_land_pos':[], 'test_mse_land_pos_SE':[], 'central_scasim_dnn':[], 'central_scasim_dnn_SE':[], 'central_scasim_human':[], 'central_scasim_human_SE':[], 'scasim_dnn':[], 'scasim_dnn_SE':[], 'scasim_human':[], 'scasim_human_SE':[]}\n",
        "\t\tlist_train = [split_list[i] for i in train_idx]\n",
        "\t\tlist_test = [split_list[i] for i in test_idx]\n",
        "\n",
        "\t\t# create train validation split for training the models:\n",
        "\t\tkf_val = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
        "\t\tfor train_index, val_index in kf_val.split(list_train):\n",
        "\t\t\t# we only evaluate a single fold\n",
        "\t\t\tbreak\n",
        "\t\tlist_train_net = [list_train[i] for i in train_index]\n",
        "\t\tlist_val_net = [list_train[i] for i in val_index]\n",
        "\n",
        "\t\tsn_list_train = list_train_net\n",
        "\t\tsn_list_val = list_val_net\n",
        "\t\tsn_list_test = list_test\n",
        "\t\treader_list_train, reader_list_val, reader_list_test = reader_list, reader_list, reader_list\n",
        "\n",
        "\t\t#initialize tokenizer\n",
        "\t\ttokenizer = BertTokenizer.from_pretrained(cf['model_pretrained'])\n",
        "\t\t#Preparing batch data\n",
        "\t\tdataset_train = BSCdataset(word_info_df, eyemovement_df, cf, reader_list_train, sn_list_train, tokenizer)\n",
        "\t\ttrain_dataloaderr = DataLoader(dataset_train, batch_size = cf[\"batch_size\"], shuffle = True, drop_last=True)\n",
        "\n",
        "\t\tdataset_val = BSCdataset(word_info_df, eyemovement_df, cf, reader_list_val, sn_list_val, tokenizer)\n",
        "\t\tval_dataloaderr = DataLoader(dataset_val, batch_size = cf[\"batch_size\"], shuffle = False, drop_last=True)\n",
        "\n",
        "\t\tdataset_test = BSCdataset(word_info_df, eyemovement_df, cf, reader_list_test, sn_list_test, tokenizer)\n",
        "\t\ttest_dataloaderr = DataLoader(dataset_test, batch_size = cf[\"batch_size\"], shuffle = False, drop_last=False)\n",
        "\n",
        "\t\t#z-score normalization for gaze features\n",
        "\t\tfix_dur_mean, fix_dur_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sp_fix_dur\", padding_value=0, scale=1000)\n",
        "\t\tlanding_pos_mean, landing_pos_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sp_landing_pos\", padding_value=0)\n",
        "\t\tsn_word_len_mean, sn_word_len_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sn_word_len\")\n",
        "\n",
        "\t\t# load model\n",
        "\t\tdnn = Eyettention_readerID(cf)\n",
        "\n",
        "\t\t#training\n",
        "\t\tepisode = 0\n",
        "\t\toptimizer = Adam(dnn.parameters(), lr=cf[\"lr\"])\n",
        "\t\tdnn.train()\n",
        "\t\tdnn.to(device)\n",
        "\t\tav_score = deque(maxlen=100)\n",
        "\t\tav_location_score = deque(maxlen=100)\n",
        "\t\tav_duration_score = deque(maxlen=100)\n",
        "\t\tav_land_pos_score = deque(maxlen=100)\n",
        "\t\told_score = 1e10\n",
        "\t\tsave_ep_couter = 0\n",
        "\t\tprint('Start training')\n",
        "\t\tprint(\"fold_indx\", fold_indx)\n",
        "\t\tfor episode_i in range(episode, cf[\"n_epochs\"]+1):\n",
        "\t\t\tdnn.train()\n",
        "\t\t\tprint('episode:', episode_i)\n",
        "\t\t\tcounter = 0\n",
        "\t\t\tfor batchh in train_dataloaderr:\n",
        "\t\t\t\tcounter += 1\n",
        "\t\t\t\tbatchh.keys()\n",
        "\t\t\t\tsn_ids = batchh[\"sn_ids\"].to(device)\n",
        "\t\t\t\tsn_input_ids = batchh[\"sn_input_ids\"].to(device)\n",
        "\t\t\t\tsn_attention_mask = batchh[\"sn_attention_mask\"].to(device)\n",
        "\t\t\t\tsp_input_ids = batchh[\"sp_input_ids\"].to(device)\n",
        "\t\t\t\tsp_attention_mask = batchh[\"sp_attention_mask\"].to(device)\n",
        "\t\t\t\tsp_pos = batchh[\"sp_pos\"].to(device)\n",
        "\t\t\t\tsp_landing_pos = batchh[\"sp_landing_pos\"].to(device) # [256, 40]\n",
        "\t\t\t\tsp_fix_dur = (batchh[\"sp_fix_dur\"]/1000).to(device) # [256, 40]\n",
        "\t\t\t\tsn_word_len = batchh[\"sn_word_len\"].to(device)\n",
        "\t\t\t\tsub_id = batchh[\"sub_id\"].to(device)\n",
        "\n",
        "\n",
        "\t\t\t\t# normalize gaze features (z-score normalisation)\n",
        "\t\t\t\tmask = ~torch.eq(sp_fix_dur, 0)\n",
        "\t\t\t\tsp_fix_dur = (sp_fix_dur-fix_dur_mean)/fix_dur_std * mask\n",
        "\t\t\t\tsp_fix_dur = torch.nan_to_num(sp_fix_dur) # [256, 40]\n",
        "\t\t\t\tsp_landing_pos = (sp_landing_pos - landing_pos_mean)/landing_pos_std * mask\n",
        "\t\t\t\tsp_landing_pos = torch.nan_to_num(sp_landing_pos)\n",
        "\t\t\t\tsn_word_len = (sn_word_len - sn_word_len_mean)/sn_word_len_std\n",
        "\t\t\t\tsn_word_len = torch.nan_to_num(sn_word_len)\n",
        "\n",
        "\t\t\t\t# zero old gradients\n",
        "\t\t\t\toptimizer.zero_grad()\n",
        "\t\t\t\t# predict output with DNN\n",
        "\t\t\t\tlocation_preds, duration_preds, landing_pos_preds, atten_weights = dnn(sn_emd=sn_input_ids,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_mask=sn_attention_mask,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_emd=sp_input_ids,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_pos=sp_pos,\n",
        "\t\t\t\t\t\t\t\t\t\t\tword_ids_sn=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\tword_ids_sp=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_fix_dur=sp_fix_dur,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_landing_pos=sp_landing_pos,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_word_len = sn_word_len,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsub_id = sub_id\n",
        "\t\t\t\t\t\t\t\t\t\t\t                                            )#[batch, step, dec_o_dim]\n",
        "\n",
        "\t\t\t\tlocation_preds = location_preds.permute(0,2,1)              #[batch, dec_o_dim, step]\n",
        "\n",
        "\t\t\t\t#prepare label and mask\n",
        "\t\t\t\t# Compute loss for fixation locations\n",
        "\t\t\t\tpad_mask, label = load_label(sp_pos, cf, le, device)\n",
        "\t\t\t\tloss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\t\t\t\tbatch_location_error = torch.mean(torch.masked_select(loss(location_preds, label), ~pad_mask))\n",
        "\n",
        "\t\t\t\t# Compute loss for fixation durations\n",
        "\t\t\t\tduration_labels = sp_fix_dur[:, :39] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\tduration_preds = duration_preds.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\tdur_loss = nn.MSELoss(reduction=\"none\")\n",
        "\t\t\t\tbatch_duration_error = torch.mean(dur_loss(duration_preds, duration_labels))\n",
        "\n",
        "\t\t\t\t# Compute loss for landing position\n",
        "\t\t\t\tlanding_pos_labels = sp_landing_pos[:, :39] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\tlanding_pos_preds = landing_pos_preds.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\tland_pos_loss = nn.MSELoss(reduction=\"none\")\n",
        "\t\t\t\tbatch_land_pos_error = torch.mean(land_pos_loss(landing_pos_preds, landing_pos_labels))\n",
        "\n",
        "\t\t\t\t# Combined loss for both location and duration\n",
        "\t\t\t\tbatch_error = batch_location_error + batch_duration_error + batch_land_pos_error\n",
        "\n",
        "\t\t\t\t# backpropagate loss\n",
        "\t\t\t\tbatch_error.backward()\n",
        "\t\t\t\t# clip gradients\n",
        "\t\t\t\tgradient_clipping(dnn, cf[\"max_grad_norm\"])\n",
        "\n",
        "\t\t\t\t#learn\n",
        "\t\t\t\toptimizer.step()\n",
        "\t\t\t\tav_location_score.append(batch_location_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_duration_score.append(batch_duration_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_land_pos_score.append(batch_land_pos_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_score.append(batch_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tprint('counter:',counter)\n",
        "\t\t\t\tprint('\\rSample {}\\tLocation Loss: {:.10f}\\tDuration Loss: {:.10f}\\tLanding position Loss: {:.10f}'.format(\n",
        "          counter, np.mean(av_location_score), np.mean(av_duration_score), np.mean(av_land_pos_score)), end=\" \")\n",
        "\t\t\tloss_dict['train_loss'].append(np.mean(av_score))\n",
        "\n",
        "\t\t\tlocation_val_loss = []\n",
        "\t\t\tduration_val_loss = []\n",
        "\t\t\tland_pos_val_loss = []\n",
        "\t\t\tval_loss = []\n",
        "\t\t\tdnn.eval()\n",
        "\t\t\tfor batchh in val_dataloaderr:\n",
        "\t\t\t\twith torch.no_grad():\n",
        "\t\t\t\t\tsn_ids_val = batchh[\"sn_ids\"].to(device)\n",
        "\t\t\t\t\tsn_input_ids_val = batchh[\"sn_input_ids\"].to(device)\n",
        "\t\t\t\t\tsn_attention_mask_val = batchh[\"sn_attention_mask\"].to(device)\n",
        "\t\t\t\t\tsp_input_ids_val = batchh[\"sp_input_ids\"].to(device)\n",
        "\t\t\t\t\tsp_attention_mask_val = batchh[\"sp_attention_mask\"].to(device)\n",
        "\t\t\t\t\tsp_pos_val = batchh[\"sp_pos\"].to(device)\n",
        "\t\t\t\t\tsp_landing_pos_val = batchh[\"sp_landing_pos\"].to(device)\n",
        "\t\t\t\t\tsp_fix_dur_val = (batchh[\"sp_fix_dur\"]/1000).to(device)\n",
        "\t\t\t\t\tsn_word_len_val = batchh[\"sn_word_len\"].to(device)\n",
        "\t\t\t\t\tsub_id_val = batchh[\"sub_id\"].to(device)\n",
        "\n",
        "\t\t\t\t\t#normalize gaze features\n",
        "\t\t\t\t\tmask = ~torch.eq(sp_fix_dur_val, 0)\n",
        "\t\t\t\t\tsp_fix_dur_val = (sp_fix_dur_val-fix_dur_mean)/fix_dur_std * mask\n",
        "\t\t\t\t\tsp_landing_pos_val = (sp_landing_pos_val - landing_pos_mean)/landing_pos_std * mask\n",
        "\t\t\t\t\tsp_fix_dur_val = torch.nan_to_num(sp_fix_dur_val)\n",
        "\t\t\t\t\tsp_landing_pos_val = torch.nan_to_num(sp_landing_pos_val)\n",
        "\t\t\t\t\tsn_word_len_val = (sn_word_len_val - sn_word_len_mean)/sn_word_len_std\n",
        "\t\t\t\t\tsn_word_len_val = torch.nan_to_num(sn_word_len_val)\n",
        "\n",
        "\t\t\t\t\tlocation_preds_val, duration_preds_val, landing_pos_preds_val, atten_weights_val = dnn(sn_emd=sn_input_ids_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_mask=sn_attention_mask_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_emd=sp_input_ids_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_pos=sp_pos_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sn=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sp=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_fix_dur=sp_fix_dur_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_landing_pos=sp_landing_pos_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_word_len = sn_word_len_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsub_id = sub_id_val)#[batch, step, dec_o_dim]\n",
        "\t\t\t\t\tlocation_preds_val = location_preds_val.permute(0,2,1)              #[batch, dec_o_dim, step\n",
        "\n",
        "\t\t\t\t\t# Compute location prediction error\n",
        "\t\t\t\t\tloss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\t\t\t\t\tpad_mask_val, label_val = load_label(sp_pos_val, cf, le, device)\n",
        "\t\t\t\t\tlocation_error_val = torch.mean(torch.masked_select(loss(location_preds_val, label_val), ~pad_mask_val))\n",
        "\t\t\t\t\tlocation_val_loss.append(location_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\t# Compute duration prediction error\n",
        "\t\t\t\t\tduration_labels_val = sp_fix_dur_val[:, :39] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\t\tduration_preds_val = duration_preds_val.squeeze(-1)\n",
        "\t\t\t\t\tduration_error_val = torch.mean(dur_loss(duration_preds_val, duration_labels_val))\n",
        "\t\t\t\t\tduration_val_loss.append(duration_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\t# Compute loss for landing position\n",
        "\t\t\t\t\tlanding_pos_labels_val = sp_landing_pos_val[:, :39] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\t\tlanding_pos_preds_val = landing_pos_preds_val.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\t\tland_pos_error_val = torch.mean(land_pos_loss(landing_pos_preds_val, landing_pos_labels_val))\n",
        "\t\t\t\t\tland_pos_val_loss.append(land_pos_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\tcombined_loss = location_error_val + duration_error_val + land_pos_error_val\n",
        "\t\t\t\t\tval_loss.append(combined_loss.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\tprint('\\nValidation loss for locations {} \\n'.format(np.mean(location_val_loss)))\n",
        "\t\t\tprint('\\nValidation loss for duration {} \\n'.format(np.mean(duration_val_loss)))\n",
        "\t\t\tprint('\\nValidation loss for landing position {} \\n'.format(np.mean(land_pos_val_loss)))\n",
        "\t\t\tloss_dict['val_loss'].append(np.mean(val_loss))\n",
        "\n",
        "\t\t\tif np.mean(val_loss) < old_score:\n",
        "\t\t\t\t# save model if val loss is smallest\n",
        "\t\t\t\ttorch.save(dnn.state_dict(), '{}/BSC_Eyettention_Reader_{}_Fold{}}.pth'.format(save_data_folder, cf[\"subid_emb_size\"], fold_indx))\n",
        "\t\t\t\told_score = np.mean(val_loss)\n",
        "\t\t\t\tprint('\\nsaved model state dict\\n')\n",
        "\t\t\t\tsave_ep_couter = episode_i\n",
        "\t\t\telse:\n",
        "\t\t\t\t#early stopping\n",
        "\t\t\t\tif episode_i - save_ep_couter >= cf[\"earlystop_patience\"]:\n",
        "\t\t\t\t\tbreak\n",
        "\t\tfold_indx += 1\n",
        "\n",
        "\t\t#evaluation\n",
        "\t\tdnn.eval()\n",
        "\t\tres_llh=[]\n",
        "\t\tres_mse_dur = []\n",
        "\t\tres_mse_land_pos = []\n",
        "\t\tres_central_scasim_human = []\n",
        "\t\tres_central_scasim_dnn = []\n",
        "\t\tres_scasim_human = []\n",
        "\t\tres_scasim_dnn = []\n",
        "\t\tdnn.load_state_dict(torch.load(os.path.join(save_data_folder, f'BSC_Eyettention_Reader_{cf[\"subid_emb_size\"]}_Fold{fold_indx}.pth'), map_location='cpu'))\n",
        "\t\tdnn.to(device)\n",
        "\t\tbatch_indx = 0\n",
        "\t\tprint(\"Evaluating for fold\", fold_indx)\n",
        "\t\tfor batchh in test_dataloaderr:\n",
        "\t\t\twith torch.no_grad():\n",
        "\t\t\t\tsn_ids_test = batchh[\"sn_ids\"].to(device)\n",
        "\t\t\t\tsn_input_ids_test = batchh[\"sn_input_ids\"].to(device)\n",
        "\t\t\t\tsn_attention_mask_test = batchh[\"sn_attention_mask\"].to(device)\n",
        "\t\t\t\tsp_input_ids_test = batchh[\"sp_input_ids\"].to(device)\n",
        "\t\t\t\tsp_attention_mask_test = batchh[\"sp_attention_mask\"].to(device)\n",
        "\t\t\t\tsp_pos_test = batchh[\"sp_pos\"].to(device) # 28: '<Sep>', 29: '<'Pad'>'\n",
        "\t\t\t\tsp_landing_pos_test = batchh[\"sp_landing_pos\"].to(device)\n",
        "\t\t\t\tsp_fix_dur_test = (batchh[\"sp_fix_dur\"]/1000).to(device)\n",
        "\t\t\t\tsn_word_len_test = batchh[\"sn_word_len\"].to(device)\n",
        "\t\t\t\tsub_id_test = batchh[\"sub_id\"].to(device)\n",
        "\n",
        "\n",
        "\t\t\t\t#normalize gaze features\n",
        "\t\t\t\tmask = ~torch.eq(sp_fix_dur_test, 0)\n",
        "\t\t\t\tsp_fix_dur_test = (sp_fix_dur_test-fix_dur_mean)/fix_dur_std * mask\n",
        "\t\t\t\tsp_landing_pos_test = (sp_landing_pos_test - landing_pos_mean)/landing_pos_std * mask\n",
        "\t\t\t\tsp_fix_dur_test = torch.nan_to_num(sp_fix_dur_test)\n",
        "\t\t\t\tsp_landing_pos_test = torch.nan_to_num(sp_landing_pos_test)\n",
        "\t\t\t\tsn_word_len_test = (sn_word_len_test - sn_word_len_mean)/sn_word_len_std\n",
        "\t\t\t\tsn_word_len_test = torch.nan_to_num(sn_word_len_test)\n",
        "\n",
        "\t\t\t\tlocation_preds_test, duration_preds_test, landing_pos_preds_test, atten_weights_test = dnn(sn_emd=sn_input_ids_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_mask=sn_attention_mask_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_emd=sp_input_ids_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_pos=sp_pos_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sn=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sp=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_fix_dur=sp_fix_dur_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_landing_pos=sp_landing_pos_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_word_len = sn_word_len_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsub_id = sub_id_test\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t) #[batch, step, dec_o_dim]\n",
        "\n",
        "\n",
        "\t\t\t\t########## Evaluate location predictions ##########\n",
        "\t\t\t\tm = nn.Softmax(dim=2)\n",
        "\t\t\t\tlocation_preds_test = m(location_preds_test).detach().to('cpu').numpy()\n",
        "\n",
        "\t\t\t\t#prepare label and mask\n",
        "\t\t\t\tpad_mask_test, label_test = load_label(sp_pos_test, cf, le, 'cpu')\n",
        "\t\t\t\t#compute log likelihood for the batch samples\n",
        "\t\t\t\tres_batch = eval_log_llh(location_preds_test, label_test, pad_mask_test)\n",
        "\t\t\t\tres_llh.append(np.array(res_batch))\n",
        "\n",
        "\t\t\t\tprint(\"######### Eyettention Reader 2.0 model evaluation ##########\")\n",
        "\t\t\t\tduration_preds_test = duration_preds_test.squeeze(-1)\n",
        "\t\t\t\tduration_labels_test = sp_fix_dur_test[:, :39]\n",
        "\t\t\t\ttest_mask = mask[:, :39]\n",
        "\t\t\t\tmse_dur = eval_mse(duration_preds_test, duration_labels_test, test_mask)\n",
        "\t\t\t\tprint(\"MSE for durations\", np.mean(mse_dur))\n",
        "\t\t\t\tres_mse_dur.append(np.array(mse_dur))\n",
        "\n",
        "\t\t\t\tlanding_pos_preds_test = landing_pos_preds_test.squeeze(-1)\n",
        "\t\t\t\tlanding_pos_labels_test = sp_landing_pos_test[:, :39]\n",
        "\t\t\t\tmse_landing_pos = eval_mse(landing_pos_preds_test, landing_pos_labels_test, test_mask)\n",
        "\t\t\t\tprint(\"MSE for landing positions\", np.mean(mse_landing_pos))\n",
        "\t\t\t\tres_mse_land_pos.append(np.array(mse_landing_pos))\n",
        "\n",
        "\n",
        "\t\t\t\tif bool(scanpath_gen_flag) == True:\n",
        "\t\t\t\t\tsn_len = (torch.sum(sn_attention_mask_test, axis=1) - 2).detach().to('cpu').numpy()\n",
        "\t\t\t\t\t# compute the scan path generated from the model when the first CLS token is given\n",
        "\t\t\t\t\tsp_dnn, _, dur_dnn, land_pos_dnn = dnn.scanpath_generation(sn_emd=sn_input_ids_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sn_mask=sn_attention_mask_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t word_ids_sn=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sn_word_len = sn_word_len_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t le=le,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sp_fix_dur=sp_fix_dur_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sp_landing_pos = sp_landing_pos_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sub_id = sub_id_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t max_pred_len=cf['max_pred_len'])\n",
        "\n",
        "\t\t\t\t\tsp_dnn, sp_human = prepare_scanpath(sp_dnn.detach().to('cpu').numpy(),\n",
        "                                              dur_dnn.detach().to('cpu').numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tland_pos_dnn.detach().to('cpu').numpy(),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_len, sp_pos_test,\n",
        "                                              sp_fix_dur_test, sp_landing_pos_test, cf, sn_ids_test,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfix_dur_mean, fix_dur_std, landing_pos_mean, landing_pos_std)\n",
        "\n",
        "\t\t\t\t\tsp_dnn_list.extend(sp_dnn)\n",
        "\t\t\t\t\tsp_human_list.extend(sp_human)\n",
        "\n",
        "\t\t\t\t\tsp_dnn = convert_sp_to_lists(sp_dnn)\n",
        "\t\t\t\t\tsp_human = convert_sp_to_lists(sp_human)\n",
        "\t\t\t\t\tsp_human = modify_landing_pos(sp_human.copy())\n",
        "\t\t\t\t\tsp_dnn = modify_landing_pos(sp_dnn.copy())\n",
        "\t\t\t\t\trandom_sp = sample_random_sp(\"BSC\", sp_human)\n",
        "\t\t\t\t\trandom_sp = convert_sp_to_lists(random_sp)\n",
        "\t\t\t\t\trandom_sp = modify_landing_pos(random_sp.copy())\n",
        "\n",
        "\t\t\t\t\tscasim_scores_dnn = compute_scasim(sp_dnn, sp_human)\n",
        "\t\t\t\t\tres_scasim_dnn.append(scasim_scores_dnn)\n",
        "\t\t\t\t\tprint(\"Mean scasim dnn\", np.mean(scasim_scores_dnn))\n",
        "\t\t\t\t\tscasim_scores_human = compute_scasim(sp_human, random_sp)\n",
        "\t\t\t\t\tres_scasim_human.append(scasim_scores_human)\n",
        "\t\t\t\t\tprint(\"Mean scasim human\", np.mean(scasim_scores_human))\n",
        "\n",
        "\t\t\t\t\tcentral_scasim_scores_dnn = compute_central_scasim(\"BSC_most_central_sp.txt\", sp_dnn)\n",
        "\t\t\t\t\tcentral_scasim_scores_human = compute_central_scasim(\"BSC_most_central_sp.txt\", sp_human)\n",
        "\t\t\t\t\tres_central_scasim_dnn.append(np.array(central_scasim_scores_dnn))\n",
        "\t\t\t\t\tres_central_scasim_human.append(np.array(central_scasim_scores_human))\n",
        "\t\t\t\t\tprint(\"Mean central scasim dnn\", np.mean(central_scasim_scores_dnn))\n",
        "\t\t\t\t\tprint(\"Mean central scasim human\", np.mean(central_scasim_scores_human))\n",
        "\n",
        "\t\t\t\tbatch_indx +=1\n",
        "\n",
        "\t\tres_llh = np.concatenate(res_llh).ravel()\n",
        "\t\tloss_dict['test_ll'].append(res_llh)\n",
        "\t\tres_mse_dur = np.concatenate(res_mse_dur).ravel()\n",
        "\t\tloss_dict['test_mse_dur'].append(res_mse_dur)\n",
        "\t\tres_mse_land_pos = np.concatenate(res_mse_land_pos).ravel()\n",
        "\t\tloss_dict['test_mse_land_pos'].append(res_mse_land_pos)\n",
        "\n",
        "\t\tres_central_scasim_dnn = np.concatenate(res_central_scasim_dnn).ravel()\n",
        "\t\tloss_dict['central_scasim_dnn'].append(res_central_scasim_dnn)\n",
        "\t\tres_central_scasim_human = np.concatenate(res_central_scasim_human).ravel()\n",
        "\t\tloss_dict['central_scasim_human'].append(res_central_scasim_human)\n",
        "\t\tres_scasim_dnn = np.concatenate(res_scasim_dnn).ravel()\n",
        "\t\tloss_dict['scasim_dnn'].append(res_scasim_dnn)\n",
        "\t\tres_scasim_human = np.concatenate(res_scasim_human).ravel()\n",
        "\t\tloss_dict['scasim_human'].append(res_scasim_human)\n",
        "\n",
        "\t\tloss_dict['fix_dur_mean'] = fix_dur_mean\n",
        "\t\tloss_dict['fix_dur_std'] = fix_dur_std\n",
        "\t\tloss_dict['landing_pos_mean'] = landing_pos_mean\n",
        "\t\tloss_dict['landing_pos_std'] = landing_pos_std\n",
        "\t\tloss_dict['sn_word_len_mean'] = sn_word_len_mean\n",
        "\t\tloss_dict['sn_word_len_std'] = sn_word_len_std\n",
        "\n",
        "\t\tprint('Test likelihood is {}'.format(np.mean(res_llh)))\n",
        "\t\tloss_dict['test_ll_SE'].append(np.std(res_llh)/ np.sqrt(len(res_llh)))\n",
        "\t\tprint(\"Standard error for NLL\", np.std(res_llh)/ np.sqrt(len(res_llh)))\n",
        "\n",
        "\t\tprint('Test MSE for durations is {}'.format(np.mean(res_mse_dur)))\n",
        "\t\tloss_dict['test_mse_dur_SE'].append(np.std(res_mse_dur)/ np.sqrt(len(res_mse_dur)))\n",
        "\t\tprint(\"Standard error for MSE dur\", np.std(res_mse_dur) / np.sqrt(len(res_mse_dur)))\n",
        "\n",
        "\t\tprint('Test MSE for landing positions is {}'.format(np.mean(res_mse_land_pos)))\n",
        "\t\tloss_dict['test_mse_land_pos_SE'].append(np.std(res_mse_land_pos)/ np.sqrt(len(res_mse_land_pos)))\n",
        "\t\tprint(\"Standard error for MSE land pos\", np.std(res_mse_land_pos) / np.sqrt(len(res_mse_land_pos)))\n",
        "\n",
        "\t\tprint(\"Central Scasim dnn\", np.mean(loss_dict['central_scasim_dnn']))\n",
        "\t\tloss_dict['central_scasim_dnn_SE'].append(np.std(res_central_scasim_dnn)/ np.sqrt(len(res_central_scasim_dnn)))\n",
        "\t\tprint(\"Standard error for Central scasim DNN\", np.std(res_central_scasim_dnn) / np.sqrt(len(res_central_scasim_dnn)))\n",
        "\n",
        "\t\tprint(\"Central Scasim human\", np.mean(loss_dict['central_scasim_human']))\n",
        "\t\tloss_dict['central_scasim_human_SE'].append(np.std(res_central_scasim_human)/ np.sqrt(len(res_central_scasim_human)))\n",
        "\t\tprint(\"Standard error for Central scasim human\", np.std(res_central_scasim_human) / np.sqrt(len(res_central_scasim_human)))\n",
        "\n",
        "\t\tprint(\"Scasim dnn\", np.mean(loss_dict['scasim_dnn']))\n",
        "\t\tloss_dict['scasim_dnn_SE'].append(np.std(res_scasim_dnn)/ np.sqrt(len(res_scasim_dnn)))\n",
        "\t\tprint(\"Standard error for scasim dnn\", np.std(res_scasim_dnn) / np.sqrt(len(res_scasim_dnn)))\n",
        "\n",
        "\t\tprint(\"Scasim human\", np.mean(loss_dict['scasim_human']))\n",
        "\t\tloss_dict['scasim_human_SE'].append(np.std(res_scasim_human)/ np.sqrt(len(res_scasim_human)))\n",
        "\t\tprint(\"Standard error for scasim human\", np.std(res_scasim_human) / np.sqrt(len(res_scasim_human)))\n",
        "\n",
        "\t\t#save results\n",
        "\t\twith open('{}/res_BSC_eyettention_reader_Fold{}.pickle'.format(save_data_folder, fold_indx), 'wb') as handle:\n",
        "\t\t\tpickle.dump(loss_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\t\tfold_indx += 1\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}