{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "nuclear-dream",
      "metadata": {
        "id": "nuclear-dream"
      },
      "source": [
        "# Eyettention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0978c758-ea14-4df4-97d0-6e0c1ed18428",
      "metadata": {
        "id": "0978c758-ea14-4df4-97d0-6e0c1ed18428"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import model\n",
        "import torch\n",
        "from torch.utils import model_zoo\n",
        "import pandas as pd\n",
        "from utils import *\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam, RMSprop\n",
        "from transformers import BertTokenizerFast\n",
        "from model import Eyettention, Eyettention_readerID\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from torch.nn.functional import cross_entropy, softmax\n",
        "from collections import deque\n",
        "import pickle\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import random\n",
        "from collections import Counter\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8dfb0f8-8775-4609-b75c-6052916ca9c0",
      "metadata": {
        "id": "c8dfb0f8-8775-4609-b75c-6052916ca9c0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "save_data_folder = \"./drive/MyDrive/results/celer\"\n",
        "DEVICE = 'cuda'\n",
        "#DEVICE = 'cpu'\n",
        "scanpath_gen_flag = True\n",
        "atten_type = \"local_g\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4l7DoNdYwUn9",
      "metadata": {
        "id": "4l7DoNdYwUn9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e085041-7c16-44b4-9129-bf667f64c552",
      "metadata": {
        "id": "6e085041-7c16-44b4-9129-bf667f64c552"
      },
      "source": [
        "**Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28WYhnrePEZj",
      "metadata": {
        "id": "28WYhnrePEZj"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "\tgpu = 0\n",
        "\n",
        "\ttorch.set_default_tensor_type('torch.FloatTensor')\n",
        "\tavailbl = torch.cuda.is_available()\n",
        "\tif availbl:\n",
        "\t\tdevice = f'cuda:{gpu}'\n",
        "\telse:\n",
        "\t\tdevice = 'cpu'\n",
        "\ttorch.cuda.set_device(gpu)\n",
        "\n",
        "\tcf = {\"model_pretrained\": \"bert-base-cased\",\n",
        "\t\t\t\"lr\": 1e-3,\n",
        "\t\t\t\"max_grad_norm\": 10,\n",
        "\t\t\t\"n_epochs\": 200,  # 1000\n",
        "\t\t\t\"n_folds\": 5,\n",
        "\t\t\t\"dataset\": 'celer',\n",
        "\t\t\t\"atten_type\": 'local-g',\n",
        "\t\t\t\"batch_size\": 128,\n",
        "\t\t\t\"max_sn_len\": 67, #include start token and end token\n",
        "\t\t\t\"max_sn_token\": 95,\n",
        "\t\t\t\"max_sp_len\": 185, #include start token and end token\n",
        "\t\t\t\"max_sp_token\": 395,\n",
        "\t\t\t\"norm_type\": \"z-score\",\n",
        "\t\t\t\"earlystop_patience\": 50,\n",
        "\t\t\t\"max_pred_len\": 60\n",
        "\t\t\t}\n",
        "\n",
        "\t#Encode the label into interger categories, setting the exclusive category 'cf[\"max_sn_len\"]-1' as the end sign\n",
        "\tle = LabelEncoder()\n",
        "\tle.fit(np.append(np.arange(-cf[\"max_sn_len\"]+3, cf[\"max_sn_len\"]-1), cf[\"max_sn_len\"]-1))\n",
        "\t#le.classes_\n",
        "\n",
        "\t#load corpus\n",
        "\tword_info_df, _, eyemovement_df = load_corpus(cf[\"dataset\"])\n",
        "\tword_info_df_val, _, eyemovement_df_val = load_corpus(\"zuco2\")\n",
        "\n",
        "\treader_list = celer_load_native_speaker()\n",
        "\t#Make list with sentence index\n",
        "\tsn_list = np.unique(word_info_df[word_info_df['list'].isin(reader_list)].sentenceid.values).tolist()\n",
        "\n",
        "\tsent_dict = convert_sent_id(sn_list)\n",
        "\n",
        "\trandom.seed(0)\n",
        "\tfold_indx = 0\n",
        "\n",
        "\treader_list_val = np.unique(\n",
        "            eyemovement_df_val.id.values).tolist()\n",
        "\tsn_list_val = np.unique(eyemovement_df_val.sn.values).tolist()\n",
        "\n",
        "\tfor i in range(5):\n",
        "\t\tprint('Sampling time:', i)\n",
        "\t\tloss_dict = {'val_loss':[], 'train_loss':[], 'test_ll':[], 'test_ll_SE':[], 'test_mse_dur':[], 'test_mse_dur_SE':[], 'test_mse_land_pos':[], 'test_mse_land_pos_SE':[], 'central_scasim_dnn':[], 'central_scasim_dnn_SE':[], 'central_scasim_human':[], 'central_scasim_human_SE':[], 'scasim_dnn':[], 'scasim_dnn_SE':[], 'scasim_human':[], 'scasim_human_SE':[], 'uniform_scasim':[], 'uniform_scasim_SE':[], 'uniform_central_scasim':[], 'uniform_central_scasim_SE':[], 'uniform_nll_SE':[], 'uniform_nll':[], 'uniform_mse_dur_SE':[], 'uniform_mse_dur':[], 'uniform_mse_land_pos_SE':[], 'uniform_mse_land_pos':[]}\n",
        "\n",
        "\t\treader_list_train = random.sample(reader_list, int(np.ceil(len(reader_list) * 0.6)))\n",
        "\t\tsn_list_train = random.sample(sn_list, int(np.ceil(len(sn_list) * 0.6)))\n",
        "\n",
        "\t\treader_list_val = random.sample(reader_list_val, int(np.ceil(len(reader_list_val) * 0.3)))\n",
        "\t\tsn_list_val = random.sample(sn_list_val, int(np.ceil(len(sn_list_val) * 0.3)))\n",
        "\n",
        "\t\t#initialize tokenizer\n",
        "\t\ttokenizer = BertTokenizerFast.from_pretrained(cf['model_pretrained'])\n",
        "\t\tfiltered_sent_dict_train = get_relevant_sent_dict(sent_dict, sn_list_train)\n",
        "\n",
        "\t\t#Preparing batch data\n",
        "\t\tdataset_train = celerdataset(word_info_df, eyemovement_df, cf, reader_list_train, sn_list_train, tokenizer, filtered_sent_dict_train)\n",
        "\t\ttrain_dataloaderr = DataLoader(dataset_train, batch_size = cf[\"batch_size\"], shuffle = True, drop_last=True)\n",
        "\n",
        "\t\tdataset_val = ZuCoDataset(word_info_df_val, eyemovement_df_val, cf, reader_list_val, sn_list_val, tokenizer)\n",
        "\t\tval_dataloaderr = DataLoader(dataset_val, batch_size = cf[\"batch_size\"], shuffle = False, drop_last=True)\n",
        "\n",
        "\t\t#z-score normalization for gaze features\n",
        "\t\tfix_dur_mean, fix_dur_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sp_fix_dur\", padding_value=0, scale=1000)\n",
        "\t\tlanding_pos_mean, landing_pos_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sp_landing_pos\", padding_value=0)\n",
        "\t\tsn_word_len_mean, sn_word_len_std = calculate_mean_std(dataloader=train_dataloaderr, feat_key=\"sn_word_len\")\n",
        "\n",
        "\t\t# load model\n",
        "\t\tdnn = Eyettention(cf)\n",
        "\t\tprint(\"fold_indx\", fold_indx)\n",
        "\n",
        "\t\t#training\n",
        "\t\tepisode = 0\n",
        "\t\toptimizer = Adam(dnn.parameters(), lr=cf[\"lr\"])\n",
        "\t\tdnn.train()\n",
        "\t\tdnn.to(device)\n",
        "\t\tav_score = deque(maxlen=100)\n",
        "\t\tav_location_score = deque(maxlen=100)\n",
        "\t\tav_duration_score = deque(maxlen=100)\n",
        "\t\tav_land_pos_score = deque(maxlen=100)\n",
        "\t\told_score = 1e10\n",
        "\t\tsave_ep_couter = 0\n",
        "\t\tprint('Start training')\n",
        "\t\tfor episode_i in range(episode, cf[\"n_epochs\"]+1):\n",
        "\t\t\tdnn.train()\n",
        "\t\t\tprint('episode:', episode_i)\n",
        "\t\t\tcounter = 0\n",
        "\t\t\tfor batchh in train_dataloaderr:\n",
        "\t\t\t\tcounter += 1\n",
        "\t\t\t\tbatchh.keys()\n",
        "\t\t\t\tsn_ids = batchh[\"sn_ids\"].to(device)\n",
        "\t\t\t\tsn_input_ids = batchh[\"sn_input_ids\"].to(device)\n",
        "\t\t\t\tsn_attention_mask = batchh[\"sn_attention_mask\"].to(device)\n",
        "\t\t\t\tword_ids_sn = batchh[\"word_ids_sn\"].to(device)\n",
        "\t\t\t\tsn_word_len = batchh[\"sn_word_len\"].to(device)\n",
        "\n",
        "\t\t\t\tsp_input_ids = batchh[\"sp_input_ids\"].to(device)\n",
        "\t\t\t\tsp_attention_mask = batchh[\"sp_attention_mask\"].to(device)\n",
        "\t\t\t\tword_ids_sp = batchh[\"word_ids_sp\"].to(device)\n",
        "\n",
        "\t\t\t\tsp_pos = batchh[\"sp_pos\"].to(device)\n",
        "\t\t\t\tsp_landing_pos = batchh[\"sp_landing_pos\"].to(device) # [256, 40]\n",
        "\t\t\t\tsp_fix_dur = (batchh[\"sp_fix_dur\"]/1000).to(device) # [256, 40]\n",
        "\n",
        "\t\t\t\t# normalize gaze features (z-score normalisation)\n",
        "\t\t\t\tmask = ~torch.eq(sp_fix_dur, 0)\n",
        "\t\t\t\tsp_fix_dur = (sp_fix_dur-fix_dur_mean)/fix_dur_std * mask\n",
        "\t\t\t\tsp_fix_dur = torch.nan_to_num(sp_fix_dur) # [256, 40]\n",
        "\t\t\t\tsp_landing_pos = (sp_landing_pos - landing_pos_mean)/landing_pos_std * mask\n",
        "\t\t\t\tsp_landing_pos = torch.nan_to_num(sp_landing_pos)\n",
        "\t\t\t\tsn_word_len = (sn_word_len - sn_word_len_mean)/sn_word_len_std\n",
        "\t\t\t\tsn_word_len = torch.nan_to_num(sn_word_len)\n",
        "\n",
        "\t\t\t\t# zero old gradients\n",
        "\t\t\t\toptimizer.zero_grad()\n",
        "\t\t\t\t# predict output with DNN\n",
        "\t\t\t\tlocation_preds, duration_preds, landing_pos_preds, atten_weights = dnn(sn_emd=sn_input_ids,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_mask=sn_attention_mask,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_emd=sp_input_ids,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_pos=sp_pos,\n",
        "\t\t\t\t\t\t\t\t\t\t\tword_ids_sn=word_ids_sn,\n",
        "\t\t\t\t\t\t\t\t\t\t\tword_ids_sp=word_ids_sp,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_fix_dur=sp_fix_dur,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsp_landing_pos=sp_landing_pos,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_word_len = sn_word_len,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_word_freq= None,\n",
        "\t\t\t\t\t\t\t\t\t\t\tsn_pred = None)#[batch, step, dec_o_dim]\n",
        "\n",
        "\t\t\t\tlocation_preds = location_preds.permute(0,2,1)              #[batch, dec_o_dim, step]\n",
        "\n",
        "\t\t\t\t#prepare label and mask\n",
        "\t\t\t\t# Compute loss for fixation locations\n",
        "\t\t\t\tpad_mask, label = load_label(sp_pos, cf, le, device)\n",
        "\t\t\t\tloss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\t\t\t\tbatch_location_error = torch.mean(torch.masked_select(loss(location_preds, label), ~pad_mask))\n",
        "\n",
        "\t\t\t\t# Compute loss for fixation durations\n",
        "\t\t\t\tduration_labels = sp_fix_dur[:, :184] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\tduration_preds = duration_preds.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\tdur_loss = nn.MSELoss(reduction=\"none\")\n",
        "\t\t\t\tdur_mask = mask[:, :184]\n",
        "\t\t\t\tbatch_duration_error = torch.mean(\n",
        "                    torch.masked_select(dur_loss(duration_preds, duration_labels), dur_mask))\n",
        "\n",
        "\t\t\t\t# Compute loss for landing position\n",
        "\t\t\t\tlanding_pos_labels = sp_landing_pos[:, :184] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\tlanding_pos_preds = landing_pos_preds.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\tland_pos_loss = nn.MSELoss(reduction=\"none\")\n",
        "\t\t\t\tland_pos_mask = mask[:, :184]\n",
        "\t\t\t\tbatch_land_pos_error = torch.mean(\n",
        "                    torch.masked_select(land_pos_loss(landing_pos_preds, landing_pos_labels), land_pos_mask))\n",
        "\n",
        "\t\t\t\t# Combined loss for both location and duration\n",
        "\t\t\t\tbatch_error = batch_location_error +  batch_duration_error + batch_land_pos_error\n",
        "\n",
        "\t\t\t\t# backpropagate loss\n",
        "\t\t\t\tbatch_error.backward()\n",
        "\t\t\t\t# clip gradients\n",
        "\t\t\t\tgradient_clipping(dnn, cf[\"max_grad_norm\"])\n",
        "\n",
        "\t\t\t\t#learn\n",
        "\t\t\t\toptimizer.step()\n",
        "\t\t\t\tav_location_score.append(batch_location_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_duration_score.append(batch_duration_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_land_pos_score.append(batch_land_pos_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tav_score.append(batch_error.to('cpu').detach().numpy())\n",
        "\t\t\t\tprint('counter:',counter)\n",
        "\t\t\t\tprint('\\rSample {}\\tLocation Loss: {:.10f}\\tDuration Loss: {:.10f}\\tLanding position Loss: {:.10f}'.format(\n",
        "          \tcounter, np.mean(av_location_score), np.mean(av_duration_score), np.mean(av_land_pos_score)), end=\" \")\n",
        "\t\t\tloss_dict['train_loss'].append(np.mean(av_score))\n",
        "\n",
        "\t\t\tlocation_val_loss = []\n",
        "\t\t\tduration_val_loss = []\n",
        "\t\t\tland_pos_val_loss = []\n",
        "\t\t\tval_loss = []\n",
        "\t\t\tdnn.eval()\n",
        "\t\t\tfor batchh in val_dataloaderr:\n",
        "\t\t\t\twith torch.no_grad():\n",
        "\t\t\t\t\tsn_ids_val = batchh[\"sn_ids\"].to(device)\n",
        "\t\t\t\t\tsn_input_ids_val = batchh[\"sn_input_ids\"].to(device)\n",
        "\t\t\t\t\tsn_attention_mask_val = batchh[\"sn_attention_mask\"].to(device)\n",
        "\t\t\t\t\tword_ids_sn_val = batchh[\"word_ids_sn\"].to(device)\n",
        "\t\t\t\t\tsn_word_len_val = batchh[\"sn_word_len\"].to(device)\n",
        "\n",
        "\t\t\t\t\tsp_input_ids_val = batchh[\"sp_input_ids\"].to(device)\n",
        "\t\t\t\t\tsp_attention_mask_val = batchh[\"sp_attention_mask\"].to(device)\n",
        "\t\t\t\t\tword_ids_sp_val = batchh[\"word_ids_sp\"].to(device)\n",
        "\n",
        "\t\t\t\t\tsp_pos_val = batchh[\"sp_pos\"].to(device)\n",
        "\t\t\t\t\tsp_landing_pos_val = batchh[\"sp_landing_pos\"].to(device)\n",
        "\t\t\t\t\tsp_fix_dur_val = (batchh[\"sp_fix_dur\"]/1000).to(device)\n",
        "\n",
        "\t\t\t\t\t#normalize gaze features\n",
        "\t\t\t\t\tmask = ~torch.eq(sp_fix_dur_val, 0)\n",
        "\t\t\t\t\tsp_fix_dur_val = (sp_fix_dur_val-fix_dur_mean)/fix_dur_std * mask\n",
        "\t\t\t\t\tsp_landing_pos_val = (sp_landing_pos_val - landing_pos_mean)/landing_pos_std * mask\n",
        "\t\t\t\t\tsp_fix_dur_val = torch.nan_to_num(sp_fix_dur_val)\n",
        "\t\t\t\t\tsp_landing_pos_val = torch.nan_to_num(sp_landing_pos_val)\n",
        "\t\t\t\t\tsn_word_len_val = (sn_word_len_val - sn_word_len_mean)/sn_word_len_std\n",
        "\t\t\t\t\tsn_word_len_val = torch.nan_to_num(sn_word_len_val)\n",
        "\n",
        "\t\t\t\t\tlocation_preds_val, duration_preds_val, landing_pos_preds_val, atten_weights_val = dnn(sn_emd=sn_input_ids_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_mask=sn_attention_mask_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_emd=sp_input_ids_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_pos=sp_pos_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sn=word_ids_sn_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tword_ids_sp=word_ids_sp_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_fix_dur=sp_fix_dur_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsp_landing_pos=sp_landing_pos_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_word_len = sn_word_len_val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tsn_word_freq= None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t      sn_pred = None)#[batch, step, dec_o_dim]\n",
        "\t\t\t\t\tlocation_preds_val = location_preds_val.permute(0,2,1)              #[batch, dec_o_dim, step\n",
        "\n",
        "\t\t\t\t\t# Compute location prediction error\n",
        "\t\t\t\t\tloss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\t\t\t\t\tpad_mask_val, label_val = load_label(sp_pos_val, cf, le, device)\n",
        "\t\t\t\t\tlocation_error_val = torch.mean(torch.masked_select(loss(location_preds_val, label_val), ~pad_mask_val))\n",
        "\t\t\t\t\tlocation_val_loss.append(location_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\t# Compute duration prediction error\n",
        "\t\t\t\t\tduration_labels_val = sp_fix_dur_val[:, :184] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\t\tduration_preds_val = duration_preds_val.squeeze(-1)\n",
        "\t\t\t\t\tdur_loss = nn.MSELoss(reduction=\"none\")\n",
        "\t\t\t\t\tdur_mask = mask[:, :184]\n",
        "\t\t\t\t\tduration_error_val = torch.mean(\n",
        "                        torch.masked_select(dur_loss(duration_preds_val, duration_labels_val), dur_mask))\n",
        "\t\t\t\t\tduration_val_loss.append(duration_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\t# Compute loss for landing position\n",
        "\t\t\t\t\tlanding_pos_labels_val = sp_landing_pos_val[:, :184] # Adjust duration_labels to match the sequence length of duration_preds\n",
        "\t\t\t\t\tlanding_pos_preds_val = landing_pos_preds_val.squeeze(-1)  # Remove extra dimension (from [256, 39, 1] to [256, 39])\n",
        "\t\t\t\t\tland_pos_mask = mask[:, :184]\n",
        "\t\t\t\t\tland_pos_error_val = torch.mean(\n",
        "                        torch.masked_select(land_pos_loss(landing_pos_preds_val, landing_pos_labels_val), land_pos_mask))\n",
        "\t\t\t\t\tland_pos_val_loss.append(land_pos_error_val.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\t\t\tcombined_loss = location_error_val + duration_error_val + land_pos_error_val\n",
        "\t\t\t\t\tval_loss.append(combined_loss.detach().to('cpu').numpy())\n",
        "\n",
        "\t\t\tprint('\\nValidation loss for locations {} \\n'.format(np.mean(location_val_loss)))\n",
        "\t\t\tprint('\\nValidation loss for duration {} \\n'.format(np.mean(duration_val_loss)))\n",
        "\t\t\tprint('\\nValidation loss for landing position {} \\n'.format(np.mean(land_pos_val_loss)))\n",
        "\t\t\tloss_dict['val_loss'].append(np.mean(val_loss))\n",
        "\n",
        "\t\t\tif np.mean(val_loss) < old_score:\n",
        "\t\t\t\t# save model if val loss is smallest\n",
        "\t\t\t\ttorch.save(dnn.state_dict(), '{}/CELER_Eyettention_fine_tuned_{}.pth'.format(save_data_folder, fold_indx))\n",
        "\t\t\t\told_score = np.mean(val_loss)\n",
        "\t\t\t\tprint('\\nsaved model state dict\\n')\n",
        "\t\t\t\tsave_ep_couter = episode_i\n",
        "\t\t\telse:\n",
        "\t\t\t\t#early stopping\n",
        "\t\t\t\tif episode_i - save_ep_couter >= cf[\"earlystop_patience\"]:\n",
        "\t\t\t\t\tbreak\n",
        "\t\tfold_indx += 1\n",
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}